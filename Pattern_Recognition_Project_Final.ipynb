{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhB7yP-EoEqc"
   },
   "source": [
    "### Unzip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-Awl5NK30kGI",
    "outputId": "1d37e6d9-7ec4-4c1d-ff62-01b3c28a759d"
   },
   "outputs": [],
   "source": [
    "# !unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2jOEyYQ4j3o"
   },
   "source": [
    "### Import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dF6_QNrZ0tBy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_dir = \"dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxHqOijD5kNy"
   },
   "source": [
    "### Import TrainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyaKrlnJoeMX"
   },
   "outputs": [],
   "source": [
    "def read_files(folder):\n",
    "  arr = []\n",
    "  for file in os.listdir(dataset_dir+folder):\n",
    "      if file.endswith(\".png\"):\n",
    "          arr.append(os.path.join(dataset_dir, folder, file))\n",
    "  return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "48nXbm__3C6n",
    "outputId": "5cedf234-564a-4f71-d702-7849035883ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/trainset/non-faces/B20_01741.png', 'dataset/trainset/non-faces/B20_01910.png', 'dataset/trainset/non-faces/B1_00053.png', 'dataset/trainset/non-faces/B20_02446.png', 'dataset/trainset/non-faces/B20_01980.png', 'dataset/trainset/non-faces/B1_00306.png', 'dataset/trainset/non-faces/B1_00392.png', 'dataset/trainset/non-faces/B20_01880.png', 'dataset/trainset/non-faces/B1_00336.png', 'dataset/trainset/non-faces/B5_00163.png', 'dataset/trainset/non-faces/B20_01621.png', 'dataset/trainset/non-faces/B20_01884.png', 'dataset/trainset/non-faces/B1_00094.png', 'dataset/trainset/non-faces/B1_00185.png', 'dataset/trainset/non-faces/B5_00124.png', 'dataset/trainset/non-faces/B5_00050.png', 'dataset/trainset/non-faces/B20_01511.png', 'dataset/trainset/non-faces/B5_00109.png', 'dataset/trainset/non-faces/B5_00240.png', 'dataset/trainset/non-faces/B1_00022.png', 'dataset/trainset/non-faces/B1_00554.png', 'dataset/trainset/non-faces/B20_01877.png', 'dataset/trainset/non-faces/B1_00416.png', 'dataset/trainset/non-faces/B20_01976.png', 'dataset/trainset/non-faces/B1_00332.png', 'dataset/trainset/non-faces/B5_00295.png', 'dataset/trainset/non-faces/B20_01888.png', 'dataset/trainset/non-faces/B1_00203.png', 'dataset/trainset/non-faces/B20_01573.png', 'dataset/trainset/non-faces/B20_01824.png', 'dataset/trainset/non-faces/B20_01753.png', 'dataset/trainset/non-faces/B5_00171.png', 'dataset/trainset/non-faces/B5_00089.png', 'dataset/trainset/non-faces/B1_00292.png', 'dataset/trainset/non-faces/B5_00137.png', 'dataset/trainset/non-faces/B1_00534.png', 'dataset/trainset/non-faces/B1_00280.png', 'dataset/trainset/non-faces/B5_00230.png', 'dataset/trainset/non-faces/B20_01652.png', 'dataset/trainset/non-faces/B20_02025.png', 'dataset/trainset/non-faces/B1_00239.png', 'dataset/trainset/non-faces/B20_01600.png', 'dataset/trainset/non-faces/B1_00513.png', 'dataset/trainset/non-faces/B20_02564.png', 'dataset/trainset/non-faces/B20_02368.png', 'dataset/trainset/non-faces/B5_00063.png', 'dataset/trainset/non-faces/B5_00133.png', 'dataset/trainset/non-faces/B20_02208.png', 'dataset/trainset/non-faces/B20_02113.png', 'dataset/trainset/non-faces/B20_01550.png', 'dataset/trainset/non-faces/B1_00175.png', 'dataset/trainset/non-faces/B20_02529.png', 'dataset/trainset/non-faces/B1_00330.png', 'dataset/trainset/non-faces/B5_00222.png', 'dataset/trainset/non-faces/B20_02598.png', 'dataset/trainset/non-faces/B1_00505.png', 'dataset/trainset/non-faces/B20_02438.png', 'dataset/trainset/non-faces/B20_02506.png', 'dataset/trainset/non-faces/B20_01991.png', 'dataset/trainset/non-faces/B5_00153.png', 'dataset/trainset/non-faces/B20_02006.png', 'dataset/trainset/non-faces/B5_00185.png', 'dataset/trainset/non-faces/B20_02414.png', 'dataset/trainset/non-faces/B1_00083.png', 'dataset/trainset/non-faces/B1_00183.png', 'dataset/trainset/non-faces/B20_01924.png', 'dataset/trainset/non-faces/B5_00328.png', 'dataset/trainset/non-faces/B20_02566.png', 'dataset/trainset/non-faces/B20_01899.png', 'dataset/trainset/non-faces/B20_02582.png', 'dataset/trainset/non-faces/B20_02484.png', 'dataset/trainset/non-faces/B20_02281.png', 'dataset/trainset/non-faces/B20_02009.png', 'dataset/trainset/non-faces/B20_02177.png', 'dataset/trainset/non-faces/B20_02515.png', 'dataset/trainset/non-faces/B1_00131.png', 'dataset/trainset/non-faces/B20_02117.png', 'dataset/trainset/non-faces/B20_02440.png', 'dataset/trainset/non-faces/B20_01911.png', 'dataset/trainset/non-faces/B20_02309.png', 'dataset/trainset/non-faces/B20_02227.png', 'dataset/trainset/non-faces/B20_02286.png', 'dataset/trainset/non-faces/B5_00033.png', 'dataset/trainset/non-faces/B20_01764.png', 'dataset/trainset/non-faces/B20_01711.png', 'dataset/trainset/non-faces/B5_00223.png', 'dataset/trainset/non-faces/B5_00263.png', 'dataset/trainset/non-faces/B20_02074.png', 'dataset/trainset/non-faces/B1_00018.png', 'dataset/trainset/non-faces/B20_02048.png', 'dataset/trainset/non-faces/B20_01830.png', 'dataset/trainset/non-faces/B20_01661.png', 'dataset/trainset/non-faces/B5_00154.png', 'dataset/trainset/non-faces/B5_00182.png', 'dataset/trainset/non-faces/B20_02053.png', 'dataset/trainset/non-faces/B20_02563.png', 'dataset/trainset/non-faces/B20_02215.png', 'dataset/trainset/non-faces/B1_00215.png', 'dataset/trainset/non-faces/B1_00440.png', 'dataset/trainset/non-faces/B20_02526.png', 'dataset/trainset/non-faces/B1_00464.png', 'dataset/trainset/non-faces/B5_00059.png', 'dataset/trainset/non-faces/B20_02010.png', 'dataset/trainset/non-faces/B1_00162.png', 'dataset/trainset/non-faces/B1_00257.png', 'dataset/trainset/non-faces/B20_01800.png', 'dataset/trainset/non-faces/B20_02583.png', 'dataset/trainset/non-faces/B20_02318.png', 'dataset/trainset/non-faces/B5_00080.png', 'dataset/trainset/non-faces/B20_01733.png', 'dataset/trainset/non-faces/B20_01853.png', 'dataset/trainset/non-faces/B1_00063.png', 'dataset/trainset/non-faces/B1_00260.png', 'dataset/trainset/non-faces/B20_01902.png', 'dataset/trainset/non-faces/B20_01543.png', 'dataset/trainset/non-faces/B20_02212.png', 'dataset/trainset/non-faces/B1_00110.png', 'dataset/trainset/non-faces/B5_00074.png', 'dataset/trainset/non-faces/B20_01713.png', 'dataset/trainset/non-faces/B20_02412.png', 'dataset/trainset/non-faces/B5_00015.png', 'dataset/trainset/non-faces/B5_00244.png', 'dataset/trainset/non-faces/B1_00502.png', 'dataset/trainset/non-faces/B20_02041.png', 'dataset/trainset/non-faces/B20_01518.png', 'dataset/trainset/non-faces/B5_00126.png', 'dataset/trainset/non-faces/B5_00023.png', 'dataset/trainset/non-faces/B1_00517.png', 'dataset/trainset/non-faces/B20_01904.png', 'dataset/trainset/non-faces/B5_00325.png', 'dataset/trainset/non-faces/B1_00255.png', 'dataset/trainset/non-faces/B5_00113.png', 'dataset/trainset/non-faces/B1_00164.png', 'dataset/trainset/non-faces/B5_00197.png', 'dataset/trainset/non-faces/B20_02152.png', 'dataset/trainset/non-faces/B20_01598.png', 'dataset/trainset/non-faces/B20_01804.png', 'dataset/trainset/non-faces/B20_01805.png', 'dataset/trainset/non-faces/B20_01921.png', 'dataset/trainset/non-faces/B1_00536.png', 'dataset/trainset/non-faces/B5_00075.png', 'dataset/trainset/non-faces/B20_02504.png', 'dataset/trainset/non-faces/B5_00016.png', 'dataset/trainset/non-faces/B20_01979.png', 'dataset/trainset/non-faces/B20_02482.png', 'dataset/trainset/non-faces/B20_01533.png', 'dataset/trainset/non-faces/B20_02470.png', 'dataset/trainset/non-faces/B5_00329.png', 'dataset/trainset/non-faces/B20_02355.png', 'dataset/trainset/non-faces/B20_02239.png', 'dataset/trainset/non-faces/B20_01959.png', 'dataset/trainset/non-faces/B1_00081.png', 'dataset/trainset/non-faces/B1_00047.png', 'dataset/trainset/non-faces/B20_02514.png', 'dataset/trainset/non-faces/B1_00240.png', 'dataset/trainset/non-faces/B20_02040.png', 'dataset/trainset/non-faces/B20_01535.png', 'dataset/trainset/non-faces/B20_01553.png', 'dataset/trainset/non-faces/B5_00202.png', 'dataset/trainset/non-faces/B1_00085.png', 'dataset/trainset/non-faces/B20_01633.png', 'dataset/trainset/non-faces/B20_02477.png', 'dataset/trainset/non-faces/B1_00015.png', 'dataset/trainset/non-faces/B1_00013.png', 'dataset/trainset/non-faces/B5_00065.png', 'dataset/trainset/non-faces/B5_00309.png', 'dataset/trainset/non-faces/B20_01992.png', 'dataset/trainset/non-faces/B20_02329.png', 'dataset/trainset/non-faces/B20_01510.png', 'dataset/trainset/non-faces/B20_01936.png', 'dataset/trainset/non-faces/B1_00494.png', 'dataset/trainset/non-faces/B20_02078.png', 'dataset/trainset/non-faces/B1_00432.png', 'dataset/trainset/non-faces/B20_02186.png', 'dataset/trainset/non-faces/B20_01521.png', 'dataset/trainset/non-faces/B1_00092.png', 'dataset/trainset/non-faces/B20_01706.png', 'dataset/trainset/non-faces/B20_01562.png', 'dataset/trainset/non-faces/B1_00396.png', 'dataset/trainset/non-faces/B20_01643.png', 'dataset/trainset/non-faces/B20_02561.png', 'dataset/trainset/non-faces/B20_02491.png', 'dataset/trainset/non-faces/B5_00243.png', 'dataset/trainset/non-faces/B20_02337.png', 'dataset/trainset/non-faces/B1_00184.png', 'dataset/trainset/non-faces/B20_02199.png', 'dataset/trainset/non-faces/B5_00315.png', 'dataset/trainset/non-faces/B20_02596.png', 'dataset/trainset/non-faces/B5_00260.png', 'dataset/trainset/non-faces/B20_01892.png', 'dataset/trainset/non-faces/B20_02202.png', 'dataset/trainset/non-faces/B5_00300.png', 'dataset/trainset/non-faces/B1_00368.png', 'dataset/trainset/non-faces/B20_02573.png', 'dataset/trainset/non-faces/B20_01844.png', 'dataset/trainset/non-faces/B20_02188.png', 'dataset/trainset/non-faces/B5_00047.png', 'dataset/trainset/non-faces/B5_00216.png', 'dataset/trainset/non-faces/B20_01546.png', 'dataset/trainset/non-faces/B20_02034.png', 'dataset/trainset/non-faces/B5_00144.png', 'dataset/trainset/non-faces/B20_01776.png', 'dataset/trainset/non-faces/B5_00213.png', 'dataset/trainset/non-faces/B20_02119.png', 'dataset/trainset/non-faces/B20_01662.png', 'dataset/trainset/non-faces/B1_00109.png', 'dataset/trainset/non-faces/B1_00514.png', 'dataset/trainset/non-faces/B20_01984.png', 'dataset/trainset/non-faces/B20_02350.png', 'dataset/trainset/non-faces/B1_00222.png', 'dataset/trainset/non-faces/B1_00498.png', 'dataset/trainset/non-faces/B20_01850.png', 'dataset/trainset/non-faces/B20_01654.png', 'dataset/trainset/non-faces/B1_00116.png', 'dataset/trainset/non-faces/B20_01545.png', 'dataset/trainset/non-faces/B20_02028.png', 'dataset/trainset/non-faces/B20_01847.png', 'dataset/trainset/non-faces/B1_00309.png', 'dataset/trainset/non-faces/B5_00183.png', 'dataset/trainset/non-faces/B5_00261.png', 'dataset/trainset/non-faces/B1_00423.png', 'dataset/trainset/non-faces/B20_01595.png', 'dataset/trainset/non-faces/B20_01669.png', 'dataset/trainset/non-faces/B1_00130.png', 'dataset/trainset/non-faces/B20_02555.png', 'dataset/trainset/non-faces/B20_01613.png', 'dataset/trainset/non-faces/B5_00083.png', 'dataset/trainset/non-faces/B20_01988.png', 'dataset/trainset/non-faces/B20_01855.png', 'dataset/trainset/non-faces/B1_00124.png', 'dataset/trainset/non-faces/B1_00294.png', 'dataset/trainset/non-faces/B1_00132.png', 'dataset/trainset/non-faces/B1_00362.png', 'dataset/trainset/non-faces/B20_02457.png', 'dataset/trainset/non-faces/B20_01525.png', 'dataset/trainset/non-faces/B20_01651.png', 'dataset/trainset/non-faces/B20_02597.png', 'dataset/trainset/non-faces/B1_00429.png', 'dataset/trainset/non-faces/B5_00178.png', 'dataset/trainset/non-faces/B20_01856.png', 'dataset/trainset/non-faces/B20_01513.png', 'dataset/trainset/non-faces/B20_01834.png', 'dataset/trainset/non-faces/B20_01670.png', 'dataset/trainset/non-faces/B20_02019.png', 'dataset/trainset/non-faces/B20_02518.png', 'dataset/trainset/non-faces/B5_00158.png', 'dataset/trainset/non-faces/B20_01948.png', 'dataset/trainset/non-faces/B20_02396.png', 'dataset/trainset/non-faces/B20_02327.png', 'dataset/trainset/non-faces/B20_02126.png', 'dataset/trainset/non-faces/B1_00512.png', 'dataset/trainset/non-faces/B5_00034.png', 'dataset/trainset/non-faces/B20_01615.png', 'dataset/trainset/non-faces/B20_02101.png', 'dataset/trainset/non-faces/B1_00458.png', 'dataset/trainset/non-faces/B1_00343.png', 'dataset/trainset/non-faces/B20_01793.png', 'dataset/trainset/non-faces/B5_00091.png', 'dataset/trainset/non-faces/B1_00403.png', 'dataset/trainset/non-faces/B20_01760.png', 'dataset/trainset/non-faces/B1_00076.png', 'dataset/trainset/non-faces/B1_00176.png', 'dataset/trainset/non-faces/B20_02142.png', 'dataset/trainset/non-faces/B20_02442.png', 'dataset/trainset/non-faces/B20_01794.png', 'dataset/trainset/non-faces/B5_00311.png', 'dataset/trainset/non-faces/B5_00220.png', 'dataset/trainset/non-faces/B20_02531.png', 'dataset/trainset/non-faces/B5_00107.png', 'dataset/trainset/non-faces/B1_00266.png', 'dataset/trainset/non-faces/B20_02065.png', 'dataset/trainset/non-faces/B20_01783.png', 'dataset/trainset/non-faces/B20_01833.png', 'dataset/trainset/non-faces/B20_02466.png', 'dataset/trainset/non-faces/B1_00135.png', 'dataset/trainset/non-faces/B1_00281.png', 'dataset/trainset/non-faces/B20_01583.png', 'dataset/trainset/non-faces/B20_02182.png', 'dataset/trainset/non-faces/B1_00115.png', 'dataset/trainset/non-faces/B5_00026.png', 'dataset/trainset/non-faces/B5_00169.png', 'dataset/trainset/non-faces/B1_00497.png', 'dataset/trainset/non-faces/B20_01677.png', 'dataset/trainset/non-faces/B5_00152.png', 'dataset/trainset/non-faces/B1_00273.png', 'dataset/trainset/non-faces/B20_01720.png', 'dataset/trainset/non-faces/B20_01792.png', 'dataset/trainset/non-faces/B20_02198.png', 'dataset/trainset/non-faces/B20_02392.png', 'dataset/trainset/non-faces/B20_01790.png', 'dataset/trainset/non-faces/B20_02361.png', 'dataset/trainset/non-faces/B20_02431.png', 'dataset/trainset/non-faces/B20_01898.png', 'dataset/trainset/non-faces/B20_02132.png', 'dataset/trainset/non-faces/B5_00211.png', 'dataset/trainset/non-faces/B1_00125.png', 'dataset/trainset/non-faces/B1_00196.png', 'dataset/trainset/non-faces/B20_01732.png', 'dataset/trainset/non-faces/B5_00237.png', 'dataset/trainset/non-faces/B20_02267.png', 'dataset/trainset/non-faces/B20_02562.png', 'dataset/trainset/non-faces/B20_02245.png', 'dataset/trainset/non-faces/B20_01739.png', 'dataset/trainset/non-faces/B5_00248.png', 'dataset/trainset/non-faces/B20_01508.png', 'dataset/trainset/non-faces/B20_01939.png', 'dataset/trainset/non-faces/B1_00099.png', 'dataset/trainset/non-faces/B20_02230.png', 'dataset/trainset/non-faces/B1_00229.png', 'dataset/trainset/non-faces/B5_00114.png', 'dataset/trainset/non-faces/B5_00155.png', 'dataset/trainset/non-faces/B20_01930.png', 'dataset/trainset/non-faces/B20_01687.png', 'dataset/trainset/non-faces/B1_00455.png', 'dataset/trainset/non-faces/B20_01894.png', 'dataset/trainset/non-faces/B20_02102.png', 'dataset/trainset/non-faces/B5_00140.png', 'dataset/trainset/non-faces/B5_00125.png', 'dataset/trainset/non-faces/B1_00364.png', 'dataset/trainset/non-faces/B20_01974.png', 'dataset/trainset/non-faces/B20_02521.png', 'dataset/trainset/non-faces/B1_00232.png', 'dataset/trainset/non-faces/B20_01971.png', 'dataset/trainset/non-faces/B5_00040.png', 'dataset/trainset/non-faces/B20_02398.png', 'dataset/trainset/non-faces/B5_00232.png', 'dataset/trainset/non-faces/B1_00385.png', 'dataset/trainset/non-faces/B5_00306.png', 'dataset/trainset/non-faces/B20_02146.png', 'dataset/trainset/non-faces/B1_00017.png', 'dataset/trainset/non-faces/B20_02402.png', 'dataset/trainset/non-faces/B1_00372.png', 'dataset/trainset/non-faces/B20_02154.png', 'dataset/trainset/non-faces/B20_01849.png', 'dataset/trainset/non-faces/B1_00148.png', 'dataset/trainset/non-faces/B5_00298.png', 'dataset/trainset/non-faces/B20_02151.png', 'dataset/trainset/non-faces/B5_00249.png', 'dataset/trainset/non-faces/B20_01650.png', 'dataset/trainset/non-faces/B1_00209.png', 'dataset/trainset/non-faces/B20_01962.png', 'dataset/trainset/non-faces/B5_00148.png', 'dataset/trainset/non-faces/B20_01772.png', 'dataset/trainset/non-faces/B20_01632.png', 'dataset/trainset/non-faces/B20_02244.png', 'dataset/trainset/non-faces/B1_00042.png', 'dataset/trainset/non-faces/B5_00039.png', 'dataset/trainset/non-faces/B5_00101.png', 'dataset/trainset/non-faces/B20_02540.png', 'dataset/trainset/non-faces/B1_00100.png', 'dataset/trainset/non-faces/B1_00486.png', 'dataset/trainset/non-faces/B20_02379.png', 'dataset/trainset/non-faces/B1_00532.png', 'dataset/trainset/non-faces/B20_02274.png', 'dataset/trainset/non-faces/B20_02312.png', 'dataset/trainset/non-faces/B1_00354.png', 'dataset/trainset/non-faces/B1_00236.png', 'dataset/trainset/non-faces/B20_02599.png', 'dataset/trainset/non-faces/B20_02261.png', 'dataset/trainset/non-faces/B1_00391.png', 'dataset/trainset/non-faces/B20_02314.png', 'dataset/trainset/non-faces/B20_01611.png', 'dataset/trainset/non-faces/B1_00219.png', 'dataset/trainset/non-faces/B20_01940.png', 'dataset/trainset/non-faces/B20_02333.png', 'dataset/trainset/non-faces/B20_01676.png', 'dataset/trainset/non-faces/B20_02140.png', 'dataset/trainset/non-faces/B1_00424.png', 'dataset/trainset/non-faces/B1_00426.png', 'dataset/trainset/non-faces/B20_02248.png', 'dataset/trainset/non-faces/B20_01841.png', 'dataset/trainset/non-faces/B20_02168.png', 'dataset/trainset/non-faces/B20_02439.png', 'dataset/trainset/non-faces/B20_01586.png', 'dataset/trainset/non-faces/B1_00422.png', 'dataset/trainset/non-faces/B5_00079.png', 'dataset/trainset/non-faces/B5_00250.png', 'dataset/trainset/non-faces/B1_00410.png', 'dataset/trainset/non-faces/B1_00151.png', 'dataset/trainset/non-faces/B1_00150.png', 'dataset/trainset/non-faces/B20_02455.png', 'dataset/trainset/non-faces/B20_02049.png', 'dataset/trainset/non-faces/B20_01555.png', 'dataset/trainset/non-faces/B1_00446.png', 'dataset/trainset/non-faces/B1_00035.png', 'dataset/trainset/non-faces/B20_02592.png', 'dataset/trainset/non-faces/B5_00209.png', 'dataset/trainset/non-faces/B20_01730.png', 'dataset/trainset/non-faces/B5_00283.png', 'dataset/trainset/non-faces/B20_01527.png', 'dataset/trainset/non-faces/B20_01599.png', 'dataset/trainset/non-faces/B20_02310.png', 'dataset/trainset/non-faces/B20_01580.png', 'dataset/trainset/non-faces/B20_02083.png', 'dataset/trainset/non-faces/B5_00025.png', 'dataset/trainset/non-faces/B1_00016.png', 'dataset/trainset/non-faces/B20_02289.png', 'dataset/trainset/non-faces/B5_00020.png', 'dataset/trainset/non-faces/B20_02194.png', 'dataset/trainset/non-faces/B20_02532.png', 'dataset/trainset/non-faces/B20_02357.png', 'dataset/trainset/non-faces/B20_01566.png', 'dataset/trainset/non-faces/B20_02157.png', 'dataset/trainset/non-faces/B1_00250.png', 'dataset/trainset/non-faces/B20_02165.png', 'dataset/trainset/non-faces/B20_02523.png', 'dataset/trainset/non-faces/B5_00164.png', 'dataset/trainset/non-faces/B1_00553.png', 'dataset/trainset/non-faces/B1_00102.png', 'dataset/trainset/non-faces/B20_02590.png', 'dataset/trainset/non-faces/B20_02144.png', 'dataset/trainset/non-faces/B20_01547.png', 'dataset/trainset/non-faces/B5_00045.png', 'dataset/trainset/non-faces/B20_01965.png', 'dataset/trainset/non-faces/B1_00463.png', 'dataset/trainset/non-faces/B1_00111.png', 'dataset/trainset/non-faces/B20_01695.png', 'dataset/trainset/non-faces/B1_00189.png', 'dataset/trainset/non-faces/B5_00013.png', 'dataset/trainset/non-faces/B1_00558.png', 'dataset/trainset/non-faces/B1_00005.png', 'dataset/trainset/non-faces/B20_02417.png', 'dataset/trainset/non-faces/B20_02441.png', 'dataset/trainset/non-faces/B1_00128.png', 'dataset/trainset/non-faces/B5_00046.png', 'dataset/trainset/non-faces/B1_00420.png', 'dataset/trainset/non-faces/B20_02089.png', 'dataset/trainset/non-faces/B20_02190.png', 'dataset/trainset/non-faces/B20_02452.png', 'dataset/trainset/non-faces/B20_01810.png', 'dataset/trainset/non-faces/B1_00253.png', 'dataset/trainset/non-faces/B20_01881.png', 'dataset/trainset/non-faces/B20_02454.png', 'dataset/trainset/non-faces/B20_01838.png', 'dataset/trainset/non-faces/B20_01719.png', 'dataset/trainset/non-faces/B1_00101.png', 'dataset/trainset/non-faces/B20_01864.png', 'dataset/trainset/non-faces/B20_02559.png', 'dataset/trainset/non-faces/B1_00025.png', 'dataset/trainset/non-faces/B20_02118.png', 'dataset/trainset/non-faces/B1_00412.png', 'dataset/trainset/non-faces/B5_00097.png', 'dataset/trainset/non-faces/B20_02107.png', 'dataset/trainset/non-faces/B20_01878.png', 'dataset/trainset/non-faces/B20_02265.png', 'dataset/trainset/non-faces/B5_00136.png', 'dataset/trainset/non-faces/B20_02602.png', 'dataset/trainset/non-faces/B20_02393.png', 'dataset/trainset/non-faces/B20_01735.png', 'dataset/trainset/non-faces/B20_02351.png', 'dataset/trainset/non-faces/B1_00523.png', 'dataset/trainset/non-faces/B20_01871.png', 'dataset/trainset/non-faces/B20_01932.png', 'dataset/trainset/non-faces/B20_02026.png', 'dataset/trainset/non-faces/B20_01724.png', 'dataset/trainset/non-faces/B20_02279.png', 'dataset/trainset/non-faces/B20_01646.png', 'dataset/trainset/non-faces/B20_02163.png', 'dataset/trainset/non-faces/B20_02451.png', 'dataset/trainset/non-faces/B5_00321.png', 'dataset/trainset/non-faces/B20_01784.png', 'dataset/trainset/non-faces/B20_01616.png', 'dataset/trainset/non-faces/B1_00408.png', 'dataset/trainset/non-faces/B1_00506.png', 'dataset/trainset/non-faces/B20_01986.png', 'dataset/trainset/non-faces/B1_00510.png', 'dataset/trainset/non-faces/B1_00145.png', 'dataset/trainset/non-faces/B20_02386.png', 'dataset/trainset/non-faces/B5_00138.png', 'dataset/trainset/non-faces/B5_00051.png', 'dataset/trainset/non-faces/B20_01785.png', 'dataset/trainset/non-faces/B1_00467.png', 'dataset/trainset/non-faces/B20_02296.png', 'dataset/trainset/non-faces/B1_00202.png', 'dataset/trainset/non-faces/B20_02112.png', 'dataset/trainset/non-faces/B5_00316.png', 'dataset/trainset/non-faces/B1_00137.png', 'dataset/trainset/non-faces/B20_02476.png', 'dataset/trainset/non-faces/B5_00275.png', 'dataset/trainset/non-faces/B5_00317.png', 'dataset/trainset/non-faces/B20_02326.png', 'dataset/trainset/non-faces/B20_01582.png', 'dataset/trainset/non-faces/B5_00041.png', 'dataset/trainset/non-faces/B1_00023.png', 'dataset/trainset/non-faces/B20_02589.png', 'dataset/trainset/non-faces/B20_02332.png', 'dataset/trainset/non-faces/B20_01998.png', 'dataset/trainset/non-faces/B20_01590.png', 'dataset/trainset/non-faces/B20_02209.png', 'dataset/trainset/non-faces/B20_02166.png', 'dataset/trainset/non-faces/B20_02270.png', 'dataset/trainset/non-faces/B20_01564.png', 'dataset/trainset/non-faces/B5_00017.png', 'dataset/trainset/non-faces/B5_00029.png', 'dataset/trainset/non-faces/B5_00254.png', 'dataset/trainset/non-faces/B20_02405.png', 'dataset/trainset/non-faces/B20_01879.png', 'dataset/trainset/non-faces/B20_01893.png', 'dataset/trainset/non-faces/B20_02558.png', 'dataset/trainset/non-faces/B20_01626.png', 'dataset/trainset/non-faces/B20_01996.png', 'dataset/trainset/non-faces/B20_02133.png', 'dataset/trainset/non-faces/B1_00326.png', 'dataset/trainset/non-faces/B5_00187.png', 'dataset/trainset/non-faces/B20_01842.png', 'dataset/trainset/non-faces/B5_00258.png', 'dataset/trainset/non-faces/B20_02125.png', 'dataset/trainset/non-faces/B1_00508.png', 'dataset/trainset/non-faces/B1_00028.png', 'dataset/trainset/non-faces/B20_01812.png', 'dataset/trainset/non-faces/B20_02007.png', 'dataset/trainset/non-faces/B20_02246.png', 'dataset/trainset/non-faces/B20_01806.png', 'dataset/trainset/non-faces/B20_02426.png', 'dataset/trainset/non-faces/B20_02155.png', 'dataset/trainset/non-faces/B20_01978.png', 'dataset/trainset/non-faces/B20_01618.png', 'dataset/trainset/non-faces/B20_02022.png', 'dataset/trainset/non-faces/B1_00267.png', 'dataset/trainset/non-faces/B20_02335.png', 'dataset/trainset/non-faces/B20_02474.png', 'dataset/trainset/non-faces/B1_00290.png', 'dataset/trainset/non-faces/B1_00542.png', 'dataset/trainset/non-faces/B1_00481.png', 'dataset/trainset/non-faces/B20_02003.png', 'dataset/trainset/non-faces/B20_02235.png', 'dataset/trainset/non-faces/B1_00483.png', 'dataset/trainset/non-faces/B1_00105.png', 'dataset/trainset/non-faces/B20_01817.png', 'dataset/trainset/non-faces/B20_01548.png', 'dataset/trainset/non-faces/B1_00401.png', 'dataset/trainset/non-faces/B1_00227.png', 'dataset/trainset/non-faces/B20_02593.png', 'dataset/trainset/non-faces/B1_00547.png', 'dataset/trainset/non-faces/B5_00175.png', 'dataset/trainset/non-faces/B5_00111.png', 'dataset/trainset/non-faces/B1_00479.png', 'dataset/trainset/non-faces/B20_02380.png', 'dataset/trainset/non-faces/B20_02486.png', 'dataset/trainset/non-faces/B5_00255.png', 'dataset/trainset/non-faces/B1_00200.png', 'dataset/trainset/non-faces/B5_00105.png', 'dataset/trainset/non-faces/B20_02090.png', 'dataset/trainset/non-faces/B20_01655.png', 'dataset/trainset/non-faces/B5_00299.png', 'dataset/trainset/non-faces/B20_01922.png', 'dataset/trainset/non-faces/B20_01994.png', 'dataset/trainset/non-faces/B5_00099.png', 'dataset/trainset/non-faces/B5_00192.png', 'dataset/trainset/non-faces/B20_02207.png', 'dataset/trainset/non-faces/B20_02195.png', 'dataset/trainset/non-faces/B1_00516.png', 'dataset/trainset/non-faces/B20_01523.png', 'dataset/trainset/non-faces/B1_00509.png', 'dataset/trainset/non-faces/B1_00032.png', 'dataset/trainset/non-faces/B20_01816.png', 'dataset/trainset/non-faces/B20_02114.png', 'dataset/trainset/non-faces/B20_01596.png', 'dataset/trainset/non-faces/B1_00297.png', 'dataset/trainset/non-faces/B20_02191.png', 'dataset/trainset/non-faces/B1_00299.png', 'dataset/trainset/non-faces/B5_00139.png', 'dataset/trainset/non-faces/B1_00112.png', 'dataset/trainset/non-faces/B20_01619.png', 'dataset/trainset/non-faces/B20_02603.png', 'dataset/trainset/non-faces/B1_00043.png', 'dataset/trainset/non-faces/B20_01656.png', 'dataset/trainset/non-faces/B5_00129.png', 'dataset/trainset/non-faces/B20_01681.png', 'dataset/trainset/non-faces/B1_00193.png', 'dataset/trainset/non-faces/B1_00445.png', 'dataset/trainset/non-faces/B20_02262.png', 'dataset/trainset/non-faces/B1_00533.png', 'dataset/trainset/non-faces/B5_00098.png', 'dataset/trainset/non-faces/B20_02349.png', 'dataset/trainset/non-faces/B20_01718.png', 'dataset/trainset/non-faces/B1_00549.png', 'dataset/trainset/non-faces/B1_00139.png', 'dataset/trainset/non-faces/B1_00296.png', 'dataset/trainset/non-faces/B1_00503.png', 'dataset/trainset/non-faces/B5_00190.png', 'dataset/trainset/non-faces/B1_00415.png', 'dataset/trainset/non-faces/B1_00540.png', 'dataset/trainset/non-faces/B1_00327.png', 'dataset/trainset/non-faces/B20_01688.png', 'dataset/trainset/non-faces/B20_02044.png', 'dataset/trainset/non-faces/B20_02369.png', 'dataset/trainset/non-faces/B20_02086.png', 'dataset/trainset/non-faces/B1_00527.png', 'dataset/trainset/non-faces/B5_00265.png', 'dataset/trainset/non-faces/B20_01827.png', 'dataset/trainset/non-faces/B1_00393.png', 'dataset/trainset/non-faces/B20_02233.png', 'dataset/trainset/non-faces/B20_01761.png', 'dataset/trainset/non-faces/B20_02027.png', 'dataset/trainset/non-faces/B1_00522.png', 'dataset/trainset/non-faces/B1_00142.png', 'dataset/trainset/non-faces/B20_02303.png', 'dataset/trainset/non-faces/B5_00010.png', 'dataset/trainset/non-faces/B1_00238.png', 'dataset/trainset/non-faces/B20_02104.png', 'dataset/trainset/non-faces/B20_02395.png', 'dataset/trainset/non-faces/B1_00221.png', 'dataset/trainset/non-faces/B20_01912.png', 'dataset/trainset/non-faces/B1_00006.png', 'dataset/trainset/non-faces/B20_01640.png', 'dataset/trainset/non-faces/B20_02121.png', 'dataset/trainset/non-faces/B20_01750.png', 'dataset/trainset/non-faces/B20_01958.png', 'dataset/trainset/non-faces/B1_00322.png', 'dataset/trainset/non-faces/B1_00400.png', 'dataset/trainset/non-faces/B1_00084.png', 'dataset/trainset/non-faces/B1_00275.png', 'dataset/trainset/non-faces/B20_01663.png', 'dataset/trainset/non-faces/B20_01941.png', 'dataset/trainset/non-faces/B20_02256.png', 'dataset/trainset/non-faces/B20_02264.png', 'dataset/trainset/non-faces/B20_01731.png', 'dataset/trainset/non-faces/B1_00334.png', 'dataset/trainset/non-faces/B1_00342.png', 'dataset/trainset/non-faces/B20_01608.png', 'dataset/trainset/non-faces/B1_00073.png', 'dataset/trainset/non-faces/B20_01625.png', 'dataset/trainset/non-faces/B1_00003.png', 'dataset/trainset/non-faces/B20_02149.png', 'dataset/trainset/non-faces/B20_02534.png', 'dataset/trainset/non-faces/B20_02055.png', 'dataset/trainset/non-faces/B1_00406.png', 'dataset/trainset/non-faces/B5_00005.png', 'dataset/trainset/non-faces/B5_00088.png', 'dataset/trainset/non-faces/B20_02050.png', 'dataset/trainset/non-faces/B5_00245.png', 'dataset/trainset/non-faces/B1_00090.png', 'dataset/trainset/non-faces/B20_01952.png', 'dataset/trainset/non-faces/B20_02411.png', 'dataset/trainset/non-faces/B20_01558.png', 'dataset/trainset/non-faces/B1_00484.png', 'dataset/trainset/non-faces/B20_02530.png', 'dataset/trainset/non-faces/B20_02552.png', 'dataset/trainset/non-faces/B1_00460.png', 'dataset/trainset/non-faces/B1_00198.png', 'dataset/trainset/non-faces/B20_01933.png', 'dataset/trainset/non-faces/B20_02098.png', 'dataset/trainset/non-faces/B5_00188.png', 'dataset/trainset/non-faces/B20_02005.png', 'dataset/trainset/non-faces/B20_02606.png', 'dataset/trainset/non-faces/B20_02384.png', 'dataset/trainset/non-faces/B20_02549.png', 'dataset/trainset/non-faces/B1_00113.png', 'dataset/trainset/non-faces/B1_00051.png', 'dataset/trainset/non-faces/B1_00538.png', 'dataset/trainset/non-faces/B20_01942.png', 'dataset/trainset/non-faces/B5_00009.png', 'dataset/trainset/non-faces/B1_00027.png', 'dataset/trainset/non-faces/B1_00461.png', 'dataset/trainset/non-faces/B20_02305.png', 'dataset/trainset/non-faces/B1_00220.png', 'dataset/trainset/non-faces/B20_02226.png', 'dataset/trainset/non-faces/B1_00235.png', 'dataset/trainset/non-faces/B20_02595.png', 'dataset/trainset/non-faces/B1_00205.png', 'dataset/trainset/non-faces/B1_00314.png', 'dataset/trainset/non-faces/B20_02046.png', 'dataset/trainset/non-faces/B1_00214.png', 'dataset/trainset/non-faces/B20_01605.png', 'dataset/trainset/non-faces/B20_02037.png', 'dataset/trainset/non-faces/B20_01529.png', 'dataset/trainset/non-faces/B20_02498.png', 'dataset/trainset/non-faces/B20_02001.png', 'dataset/trainset/non-faces/B20_02184.png', 'dataset/trainset/non-faces/B20_01587.png', 'dataset/trainset/non-faces/B20_02508.png', 'dataset/trainset/non-faces/B20_02374.png', 'dataset/trainset/non-faces/B20_01531.png', 'dataset/trainset/non-faces/B1_00453.png', 'dataset/trainset/non-faces/B20_01845.png', 'dataset/trainset/non-faces/B20_02548.png', 'dataset/trainset/non-faces/B20_01768.png', 'dataset/trainset/non-faces/B1_00487.png', 'dataset/trainset/non-faces/B20_02371.png', 'dataset/trainset/non-faces/B20_02158.png', 'dataset/trainset/non-faces/B20_02360.png', 'dataset/trainset/non-faces/B1_00559.png', 'dataset/trainset/non-faces/B20_02225.png', 'dataset/trainset/non-faces/B20_02586.png', 'dataset/trainset/non-faces/B20_02189.png', 'dataset/trainset/non-faces/B20_02323.png', 'dataset/trainset/non-faces/B20_01694.png', 'dataset/trainset/non-faces/B20_02070.png', 'dataset/trainset/non-faces/B20_02160.png', 'dataset/trainset/non-faces/B20_02413.png', 'dataset/trainset/non-faces/B1_00418.png', 'dataset/trainset/non-faces/B5_00229.png', 'dataset/trainset/non-faces/B20_01920.png', 'dataset/trainset/non-faces/B20_01623.png', 'dataset/trainset/non-faces/B20_02056.png', 'dataset/trainset/non-faces/B1_00305.png', 'dataset/trainset/non-faces/B20_02093.png', 'dataset/trainset/non-faces/B1_00316.png', 'dataset/trainset/non-faces/B20_01938.png', 'dataset/trainset/non-faces/B20_02510.png', 'dataset/trainset/non-faces/B20_01909.png', 'dataset/trainset/non-faces/B20_02313.png', 'dataset/trainset/non-faces/B20_01934.png', 'dataset/trainset/non-faces/B20_02356.png', 'dataset/trainset/non-faces/B20_02550.png', 'dataset/trainset/non-faces/B1_00069.png', 'dataset/trainset/non-faces/B20_02291.png', 'dataset/trainset/non-faces/B20_02468.png', 'dataset/trainset/non-faces/B1_00010.png', 'dataset/trainset/non-faces/B20_02334.png', 'dataset/trainset/non-faces/B20_02150.png', 'dataset/trainset/non-faces/B20_01954.png', 'dataset/trainset/non-faces/B20_01767.png', 'dataset/trainset/non-faces/B20_01859.png', 'dataset/trainset/non-faces/B1_00437.png', 'dataset/trainset/non-faces/B20_01925.png', 'dataset/trainset/non-faces/B20_02187.png', 'dataset/trainset/non-faces/B1_00007.png', 'dataset/trainset/non-faces/B20_01725.png', 'dataset/trainset/non-faces/B1_00058.png', 'dataset/trainset/non-faces/B5_00165.png', 'dataset/trainset/non-faces/B20_02181.png', 'dataset/trainset/non-faces/B20_01919.png', 'dataset/trainset/non-faces/B20_01557.png', 'dataset/trainset/non-faces/B20_02546.png', 'dataset/trainset/non-faces/B1_00485.png', 'dataset/trainset/non-faces/B5_00003.png', 'dataset/trainset/non-faces/B20_01765.png', 'dataset/trainset/non-faces/B5_00271.png', 'dataset/trainset/non-faces/B20_01751.png', 'dataset/trainset/non-faces/B20_01561.png', 'dataset/trainset/non-faces/B5_00044.png', 'dataset/trainset/non-faces/B20_02004.png', 'dataset/trainset/non-faces/B20_02567.png', 'dataset/trainset/non-faces/B1_00089.png', 'dataset/trainset/non-faces/B1_00157.png', 'dataset/trainset/non-faces/B20_01700.png', 'dataset/trainset/non-faces/B1_00048.png', 'dataset/trainset/non-faces/B20_01905.png', 'dataset/trainset/non-faces/B20_01627.png', 'dataset/trainset/non-faces/B20_02565.png', 'dataset/trainset/non-faces/B20_01579.png', 'dataset/trainset/non-faces/B5_00037.png', 'dataset/trainset/non-faces/B1_00050.png', 'dataset/trainset/non-faces/B20_01736.png', 'dataset/trainset/non-faces/B20_02325.png', 'dataset/trainset/non-faces/B20_01997.png', 'dataset/trainset/non-faces/B20_02416.png', 'dataset/trainset/non-faces/B1_00298.png', 'dataset/trainset/non-faces/B1_00551.png', 'dataset/trainset/non-faces/B20_02415.png', 'dataset/trainset/non-faces/B20_02252.png', 'dataset/trainset/non-faces/B20_01982.png', 'dataset/trainset/non-faces/B20_01955.png', 'dataset/trainset/non-faces/B20_02106.png', 'dataset/trainset/non-faces/B20_02497.png', 'dataset/trainset/non-faces/B1_00525.png', 'dataset/trainset/non-faces/B1_00366.png', 'dataset/trainset/non-faces/B20_02210.png', 'dataset/trainset/non-faces/B1_00106.png', 'dataset/trainset/non-faces/B20_02290.png', 'dataset/trainset/non-faces/B20_01813.png', 'dataset/trainset/non-faces/B1_00199.png', 'dataset/trainset/non-faces/B20_02109.png', 'dataset/trainset/non-faces/B20_02241.png', 'dataset/trainset/non-faces/B1_00293.png', 'dataset/trainset/non-faces/B20_01779.png', 'dataset/trainset/non-faces/B20_02012.png', 'dataset/trainset/non-faces/B5_00008.png', 'dataset/trainset/non-faces/B5_00085.png', 'dataset/trainset/non-faces/B5_00127.png', 'dataset/trainset/non-faces/B1_00541.png', 'dataset/trainset/non-faces/B5_00200.png', 'dataset/trainset/non-faces/B1_00249.png', 'dataset/trainset/non-faces/B1_00369.png', 'dataset/trainset/non-faces/B20_01691.png', 'dataset/trainset/non-faces/B20_02375.png', 'dataset/trainset/non-faces/B20_01895.png', 'dataset/trainset/non-faces/B20_01740.png', 'dataset/trainset/non-faces/B20_02445.png', 'dataset/trainset/non-faces/B20_01716.png', 'dataset/trainset/non-faces/B20_02220.png', 'dataset/trainset/non-faces/B20_02073.png', 'dataset/trainset/non-faces/B1_00180.png', 'dataset/trainset/non-faces/B20_01913.png', 'dataset/trainset/non-faces/B1_00337.png', 'dataset/trainset/non-faces/B1_00435.png', 'dataset/trainset/non-faces/B1_00347.png', 'dataset/trainset/non-faces/B1_00313.png', 'dataset/trainset/non-faces/B1_00161.png', 'dataset/trainset/non-faces/B20_01966.png', 'dataset/trainset/non-faces/B20_01588.png', 'dataset/trainset/non-faces/B20_02473.png', 'dataset/trainset/non-faces/B20_02443.png', 'dataset/trainset/non-faces/B1_00057.png', 'dataset/trainset/non-faces/B1_00433.png', 'dataset/trainset/non-faces/B20_01993.png', 'dataset/trainset/non-faces/B20_02319.png', 'dataset/trainset/non-faces/B5_00231.png', 'dataset/trainset/non-faces/B5_00117.png', 'dataset/trainset/non-faces/B20_02263.png', 'dataset/trainset/non-faces/B1_00465.png', 'dataset/trainset/non-faces/B20_02237.png', 'dataset/trainset/non-faces/B20_02161.png', 'dataset/trainset/non-faces/B20_02525.png', 'dataset/trainset/non-faces/B1_00353.png', 'dataset/trainset/non-faces/B20_02094.png', 'dataset/trainset/non-faces/B20_01935.png', 'dataset/trainset/non-faces/B20_02378.png', 'dataset/trainset/non-faces/B1_00370.png', 'dataset/trainset/non-faces/B20_02174.png', 'dataset/trainset/non-faces/B20_01565.png', 'dataset/trainset/non-faces/B20_01963.png', 'dataset/trainset/non-faces/B5_00100.png', 'dataset/trainset/non-faces/B5_00081.png', 'dataset/trainset/non-faces/B5_00262.png', 'dataset/trainset/non-faces/B20_02600.png', 'dataset/trainset/non-faces/B1_00384.png', 'dataset/trainset/non-faces/B20_02096.png', 'dataset/trainset/non-faces/B1_00262.png', 'dataset/trainset/non-faces/B20_01876.png', 'dataset/trainset/non-faces/B20_02502.png', 'dataset/trainset/non-faces/B20_01606.png', 'dataset/trainset/non-faces/B20_02173.png', 'dataset/trainset/non-faces/B5_00143.png', 'dataset/trainset/non-faces/B20_02255.png', 'dataset/trainset/non-faces/B1_00530.png', 'dataset/trainset/non-faces/B1_00470.png', 'dataset/trainset/non-faces/B1_00452.png', 'dataset/trainset/non-faces/B1_00365.png', 'dataset/trainset/non-faces/B20_02572.png', 'dataset/trainset/non-faces/B1_00087.png', 'dataset/trainset/non-faces/B20_02123.png', 'dataset/trainset/non-faces/B5_00331.png', 'dataset/trainset/non-faces/B1_00358.png', 'dataset/trainset/non-faces/B1_00346.png', 'dataset/trainset/non-faces/B5_00269.png', 'dataset/trainset/non-faces/B20_02047.png', 'dataset/trainset/non-faces/B20_02404.png', 'dataset/trainset/non-faces/B1_00062.png', 'dataset/trainset/non-faces/B5_00054.png', 'dataset/trainset/non-faces/B20_01815.png', 'dataset/trainset/non-faces/B5_00027.png', 'dataset/trainset/non-faces/B1_00195.png', 'dataset/trainset/non-faces/B5_00128.png', 'dataset/trainset/non-faces/B20_01937.png', 'dataset/trainset/non-faces/B1_00143.png', 'dataset/trainset/non-faces/B5_00057.png', 'dataset/trainset/non-faces/B1_00421.png', 'dataset/trainset/non-faces/B5_00224.png', 'dataset/trainset/non-faces/B1_00181.png', 'dataset/trainset/non-faces/B1_00207.png', 'dataset/trainset/non-faces/B20_02591.png', 'dataset/trainset/non-faces/B20_02147.png', 'dataset/trainset/non-faces/B1_00348.png', 'dataset/trainset/non-faces/B5_00284.png', 'dataset/trainset/non-faces/B20_02308.png', 'dataset/trainset/non-faces/B1_00493.png', 'dataset/trainset/non-faces/B20_02000.png', 'dataset/trainset/non-faces/B20_02271.png', 'dataset/trainset/non-faces/B5_00084.png', 'dataset/trainset/non-faces/B5_00212.png', 'dataset/trainset/non-faces/B20_02571.png', 'dataset/trainset/non-faces/B20_01528.png', 'dataset/trainset/non-faces/B20_01949.png', 'dataset/trainset/non-faces/B20_02522.png', 'dataset/trainset/non-faces/B20_01811.png', 'dataset/trainset/non-faces/B20_02167.png', 'dataset/trainset/non-faces/B20_02407.png', 'dataset/trainset/non-faces/B20_02213.png', 'dataset/trainset/non-faces/B20_02105.png', 'dataset/trainset/non-faces/B1_00375.png', 'dataset/trainset/non-faces/B20_02253.png', 'dataset/trainset/non-faces/B20_01809.png', 'dataset/trainset/non-faces/B20_01883.png', 'dataset/trainset/non-faces/B20_02110.png', 'dataset/trainset/non-faces/B20_02250.png', 'dataset/trainset/non-faces/B1_00436.png', 'dataset/trainset/non-faces/B1_00500.png', 'dataset/trainset/non-faces/B1_00122.png', 'dataset/trainset/non-faces/B5_00214.png', 'dataset/trainset/non-faces/B20_02388.png', 'dataset/trainset/non-faces/B20_01999.png', 'dataset/trainset/non-faces/B20_02153.png', 'dataset/trainset/non-faces/B1_00338.png', 'dataset/trainset/non-faces/B20_01539.png', 'dataset/trainset/non-faces/B20_01658.png', 'dataset/trainset/non-faces/B1_00059.png', 'dataset/trainset/non-faces/B20_02057.png', 'dataset/trainset/non-faces/B5_00294.png', 'dataset/trainset/non-faces/B20_02366.png', 'dataset/trainset/non-faces/B20_01672.png', 'dataset/trainset/non-faces/B20_01634.png', 'dataset/trainset/non-faces/B1_00188.png', 'dataset/trainset/non-faces/B1_00065.png', 'dataset/trainset/non-faces/B20_01755.png', 'dataset/trainset/non-faces/B5_00053.png', 'dataset/trainset/non-faces/B1_00243.png', 'dataset/trainset/non-faces/B20_01705.png', 'dataset/trainset/non-faces/B20_01639.png', 'dataset/trainset/non-faces/B20_02342.png', 'dataset/trainset/non-faces/B20_02406.png', 'dataset/trainset/non-faces/B20_01630.png', 'dataset/trainset/non-faces/B20_01972.png', 'dataset/trainset/non-faces/B20_01854.png', 'dataset/trainset/non-faces/B20_01983.png', 'dataset/trainset/non-faces/B1_00507.png', 'dataset/trainset/non-faces/B1_00014.png', 'dataset/trainset/non-faces/B20_01698.png', 'dataset/trainset/non-faces/B20_01836.png', 'dataset/trainset/non-faces/B20_02444.png', 'dataset/trainset/non-faces/B20_02330.png', 'dataset/trainset/non-faces/B5_00018.png', 'dataset/trainset/non-faces/B5_00157.png', 'dataset/trainset/non-faces/B20_01796.png', 'dataset/trainset/non-faces/B20_02584.png', 'dataset/trainset/non-faces/B1_00187.png', 'dataset/trainset/non-faces/B20_02604.png', 'dataset/trainset/non-faces/B1_00160.png', 'dataset/trainset/non-faces/B1_00251.png', 'dataset/trainset/non-faces/B1_00206.png', 'dataset/trainset/non-faces/B20_02449.png', 'dataset/trainset/non-faces/B1_00163.png', 'dataset/trainset/non-faces/B20_02136.png', 'dataset/trainset/non-faces/B20_01927.png', 'dataset/trainset/non-faces/B5_00180.png', 'dataset/trainset/non-faces/B20_02092.png', 'dataset/trainset/non-faces/B1_00444.png', 'dataset/trainset/non-faces/B20_02483.png', 'dataset/trainset/non-faces/B20_01807.png', 'dataset/trainset/non-faces/B20_02574.png', 'dataset/trainset/non-faces/B20_02320.png', 'dataset/trainset/non-faces/B1_00004.png', 'dataset/trainset/non-faces/B20_01551.png', 'dataset/trainset/non-faces/B20_01896.png', 'dataset/trainset/non-faces/B1_00009.png', 'dataset/trainset/non-faces/B20_01671.png', 'dataset/trainset/non-faces/B1_00283.png', 'dataset/trainset/non-faces/B20_01866.png', 'dataset/trainset/non-faces/B20_01744.png', 'dataset/trainset/non-faces/B20_02064.png', 'dataset/trainset/non-faces/B5_00327.png', 'dataset/trainset/non-faces/B1_00265.png', 'dataset/trainset/non-faces/B20_02336.png', 'dataset/trainset/non-faces/B5_00120.png', 'dataset/trainset/non-faces/B20_02061.png', 'dataset/trainset/non-faces/B1_00350.png', 'dataset/trainset/non-faces/B20_01622.png', 'dataset/trainset/non-faces/B5_00132.png', 'dataset/trainset/non-faces/B1_00074.png', 'dataset/trainset/non-faces/B5_00073.png', 'dataset/trainset/non-faces/B5_00338.png', 'dataset/trainset/non-faces/B1_00117.png', 'dataset/trainset/non-faces/B20_02164.png', 'dataset/trainset/non-faces/B1_00269.png', 'dataset/trainset/non-faces/B20_01667.png', 'dataset/trainset/non-faces/B20_02077.png', 'dataset/trainset/non-faces/B5_00339.png', 'dataset/trainset/non-faces/B20_02538.png', 'dataset/trainset/non-faces/B1_00118.png', 'dataset/trainset/non-faces/B5_00106.png', 'dataset/trainset/non-faces/B1_00414.png', 'dataset/trainset/non-faces/B20_02211.png', 'dataset/trainset/non-faces/B1_00361.png', 'dataset/trainset/non-faces/B5_00110.png', 'dataset/trainset/non-faces/B1_00477.png', 'dataset/trainset/non-faces/B20_01515.png', 'dataset/trainset/non-faces/B1_00011.png', 'dataset/trainset/non-faces/B20_01882.png', 'dataset/trainset/non-faces/B20_01757.png', 'dataset/trainset/non-faces/B20_01953.png', 'dataset/trainset/non-faces/B1_00147.png', 'dataset/trainset/non-faces/B5_00076.png', 'dataset/trainset/non-faces/B5_00067.png', 'dataset/trainset/non-faces/B20_01541.png', 'dataset/trainset/non-faces/B20_02500.png', 'dataset/trainset/non-faces/B5_00218.png', 'dataset/trainset/non-faces/B20_02280.png', 'dataset/trainset/non-faces/B1_00511.png', 'dataset/trainset/non-faces/B5_00292.png', 'dataset/trainset/non-faces/B1_00046.png', 'dataset/trainset/non-faces/B5_00043.png', 'dataset/trainset/non-faces/B1_00054.png', 'dataset/trainset/non-faces/B5_00227.png', 'dataset/trainset/non-faces/B1_00310.png', 'dataset/trainset/non-faces/B20_02302.png', 'dataset/trainset/non-faces/B5_00112.png', 'dataset/trainset/non-faces/B20_01791.png', 'dataset/trainset/non-faces/B5_00267.png', 'dataset/trainset/non-faces/B20_01831.png', 'dataset/trainset/non-faces/B5_00241.png', 'dataset/trainset/non-faces/B5_00103.png', 'dataset/trainset/non-faces/B20_02099.png', 'dataset/trainset/non-faces/B1_00378.png', 'dataset/trainset/non-faces/B20_02520.png', 'dataset/trainset/non-faces/B20_01645.png', 'dataset/trainset/non-faces/B1_00049.png', 'dataset/trainset/non-faces/B20_01601.png', 'dataset/trainset/non-faces/B5_00318.png', 'dataset/trainset/non-faces/B20_02008.png', 'dataset/trainset/non-faces/B1_00345.png', 'dataset/trainset/non-faces/B20_02383.png', 'dataset/trainset/non-faces/B1_00233.png', 'dataset/trainset/non-faces/B5_00215.png', 'dataset/trainset/non-faces/B5_00235.png', 'dataset/trainset/non-faces/B1_00173.png', 'dataset/trainset/non-faces/B20_02224.png', 'dataset/trainset/non-faces/B1_00174.png', 'dataset/trainset/non-faces/B5_00206.png', 'dataset/trainset/non-faces/B20_02410.png', 'dataset/trainset/non-faces/B1_00367.png', 'dataset/trainset/non-faces/B20_02024.png', 'dataset/trainset/non-faces/B20_02283.png', 'dataset/trainset/non-faces/B1_00204.png', 'dataset/trainset/non-faces/B20_01589.png', 'dataset/trainset/non-faces/B20_01890.png', 'dataset/trainset/non-faces/B20_01624.png', 'dataset/trainset/non-faces/B20_01572.png', 'dataset/trainset/non-faces/B1_00274.png', 'dataset/trainset/non-faces/B20_01569.png', 'dataset/trainset/non-faces/B20_02338.png', 'dataset/trainset/non-faces/B5_00049.png', 'dataset/trainset/non-faces/B20_01584.png', 'dataset/trainset/non-faces/B20_02315.png', 'dataset/trainset/non-faces/B20_02127.png', 'dataset/trainset/non-faces/B5_00272.png', 'dataset/trainset/non-faces/B5_00130.png', 'dataset/trainset/non-faces/B5_00186.png', 'dataset/trainset/non-faces/B1_00339.png', 'dataset/trainset/non-faces/B1_00133.png', 'dataset/trainset/non-faces/B20_02128.png', 'dataset/trainset/non-faces/B1_00169.png', 'dataset/trainset/non-faces/B20_02079.png', 'dataset/trainset/non-faces/B20_01964.png', 'dataset/trainset/non-faces/B20_02420.png', 'dataset/trainset/non-faces/B20_02478.png', 'dataset/trainset/non-faces/B20_01702.png', 'dataset/trainset/non-faces/B20_01743.png', 'dataset/trainset/non-faces/B20_01987.png', 'dataset/trainset/non-faces/B20_02062.png', 'dataset/trainset/non-faces/B20_01722.png', 'dataset/trainset/non-faces/B20_02364.png', 'dataset/trainset/non-faces/B20_01642.png', 'dataset/trainset/non-faces/B20_02075.png', 'dataset/trainset/non-faces/B20_02456.png', 'dataset/trainset/non-faces/B1_00170.png', 'dataset/trainset/non-faces/B20_02352.png', 'dataset/trainset/non-faces/B5_00096.png', 'dataset/trainset/non-faces/B1_00191.png', 'dataset/trainset/non-faces/B1_00545.png', 'dataset/trainset/non-faces/B20_02172.png', 'dataset/trainset/non-faces/B1_00550.png', 'dataset/trainset/non-faces/B20_02488.png', 'dataset/trainset/non-faces/B20_02519.png', 'dataset/trainset/non-faces/B5_00082.png', 'dataset/trainset/non-faces/B20_01969.png', 'dataset/trainset/non-faces/B20_02292.png', 'dataset/trainset/non-faces/B20_02228.png', 'dataset/trainset/non-faces/B20_02372.png', 'dataset/trainset/non-faces/B1_00234.png', 'dataset/trainset/non-faces/B5_00276.png', 'dataset/trainset/non-faces/B20_02401.png', 'dataset/trainset/non-faces/B5_00174.png', 'dataset/trainset/non-faces/B1_00068.png', 'dataset/trainset/non-faces/B20_02430.png', 'dataset/trainset/non-faces/B1_00194.png', 'dataset/trainset/non-faces/B20_01873.png', 'dataset/trainset/non-faces/B1_00114.png', 'dataset/trainset/non-faces/B20_02306.png', 'dataset/trainset/non-faces/B1_00371.png', 'dataset/trainset/non-faces/B20_02428.png', 'dataset/trainset/non-faces/B5_00310.png', 'dataset/trainset/non-faces/B20_02232.png', 'dataset/trainset/non-faces/B20_02577.png', 'dataset/trainset/non-faces/B20_02251.png', 'dataset/trainset/non-faces/B20_01868.png', 'dataset/trainset/non-faces/B20_01889.png', 'dataset/trainset/non-faces/B20_02317.png', 'dataset/trainset/non-faces/B20_02214.png', 'dataset/trainset/non-faces/B1_00156.png', 'dataset/trainset/non-faces/B1_00518.png', 'dataset/trainset/non-faces/B20_01721.png', 'dataset/trainset/non-faces/B20_01620.png', 'dataset/trainset/non-faces/B1_00351.png', 'dataset/trainset/non-faces/B20_02201.png', 'dataset/trainset/non-faces/B1_00088.png', 'dataset/trainset/non-faces/B20_02129.png', 'dataset/trainset/non-faces/B20_01829.png', 'dataset/trainset/non-faces/B5_00268.png', 'dataset/trainset/non-faces/B20_02103.png', 'dataset/trainset/non-faces/B5_00167.png', 'dataset/trainset/non-faces/B20_01872.png', 'dataset/trainset/non-faces/B20_01659.png', 'dataset/trainset/non-faces/B20_02180.png', 'dataset/trainset/non-faces/B1_00317.png', 'dataset/trainset/non-faces/B1_00213.png', 'dataset/trainset/non-faces/B20_01682.png', 'dataset/trainset/non-faces/B5_00288.png', 'dataset/trainset/non-faces/B20_02301.png', 'dataset/trainset/non-faces/B20_01680.png', 'dataset/trainset/non-faces/B20_02185.png', 'dataset/trainset/non-faces/B1_00355.png', 'dataset/trainset/non-faces/B1_00288.png', 'dataset/trainset/non-faces/B20_02408.png', 'dataset/trainset/non-faces/B5_00297.png', 'dataset/trainset/non-faces/B20_02331.png', 'dataset/trainset/non-faces/B5_00208.png', 'dataset/trainset/non-faces/B1_00037.png', 'dataset/trainset/non-faces/B5_00199.png', 'dataset/trainset/non-faces/B5_00336.png', 'dataset/trainset/non-faces/B1_00383.png', 'dataset/trainset/non-faces/B1_00382.png', 'dataset/trainset/non-faces/B20_01522.png', 'dataset/trainset/non-faces/B1_00399.png', 'dataset/trainset/non-faces/B20_02511.png', 'dataset/trainset/non-faces/B1_00001.png', 'dataset/trainset/non-faces/B20_02322.png', 'dataset/trainset/non-faces/B5_00181.png', 'dataset/trainset/non-faces/B20_01685.png', 'dataset/trainset/non-faces/B20_01636.png', 'dataset/trainset/non-faces/B20_02242.png', 'dataset/trainset/non-faces/B20_01560.png', 'dataset/trainset/non-faces/B20_02536.png', 'dataset/trainset/non-faces/B1_00472.png', 'dataset/trainset/non-faces/B20_02298.png', 'dataset/trainset/non-faces/B5_00330.png', 'dataset/trainset/non-faces/B20_02221.png', 'dataset/trainset/non-faces/B20_02277.png', 'dataset/trainset/non-faces/B5_00301.png', 'dataset/trainset/non-faces/B20_01875.png', 'dataset/trainset/non-faces/B1_00439.png', 'dataset/trainset/non-faces/B5_00191.png', 'dataset/trainset/non-faces/B5_00290.png', 'dataset/trainset/non-faces/B1_00254.png', 'dataset/trainset/non-faces/B20_01609.png', 'dataset/trainset/non-faces/B20_02058.png', 'dataset/trainset/non-faces/B1_00320.png', 'dataset/trainset/non-faces/B20_02171.png', 'dataset/trainset/non-faces/B1_00095.png', 'dataset/trainset/non-faces/B1_00252.png', 'dataset/trainset/non-faces/B20_01653.png', 'dataset/trainset/non-faces/B20_02067.png', 'dataset/trainset/non-faces/B5_00030.png', 'dataset/trainset/non-faces/B1_00216.png', 'dataset/trainset/non-faces/B1_00075.png', 'dataset/trainset/non-faces/B1_00031.png', 'dataset/trainset/non-faces/B20_02069.png', 'dataset/trainset/non-faces/B20_02063.png', 'dataset/trainset/non-faces/B20_01707.png', 'dataset/trainset/non-faces/B20_01617.png', 'dataset/trainset/non-faces/B1_00555.png', 'dataset/trainset/non-faces/B20_01774.png', 'dataset/trainset/non-faces/B1_00325.png', 'dataset/trainset/non-faces/B20_02394.png', 'dataset/trainset/non-faces/B20_02139.png', 'dataset/trainset/non-faces/B20_02304.png', 'dataset/trainset/non-faces/B1_00178.png', 'dataset/trainset/non-faces/B1_00153.png', 'dataset/trainset/non-faces/B20_02076.png', 'dataset/trainset/non-faces/B5_00210.png', 'dataset/trainset/non-faces/B20_01517.png', 'dataset/trainset/non-faces/B20_02400.png', 'dataset/trainset/non-faces/B1_00535.png', 'dataset/trainset/non-faces/B20_02030.png', 'dataset/trainset/non-faces/B20_01885.png', 'dataset/trainset/non-faces/B1_00223.png', 'dataset/trainset/non-faces/B5_00036.png', 'dataset/trainset/non-faces/B20_02095.png', 'dataset/trainset/non-faces/B5_00077.png', 'dataset/trainset/non-faces/B20_02316.png', 'dataset/trainset/non-faces/B20_02437.png', 'dataset/trainset/non-faces/B5_00233.png', 'dataset/trainset/non-faces/B20_02581.png', 'dataset/trainset/non-faces/B20_02359.png', 'dataset/trainset/non-faces/B20_02156.png', 'dataset/trainset/non-faces/B5_00242.png', 'dataset/trainset/non-faces/B1_00146.png', 'dataset/trainset/non-faces/B20_02425.png', 'dataset/trainset/non-faces/B20_01778.png', 'dataset/trainset/non-faces/B1_00002.png', 'dataset/trainset/non-faces/B20_02240.png', 'dataset/trainset/non-faces/B20_01762.png', 'dataset/trainset/non-faces/B20_01746.png', 'dataset/trainset/non-faces/B20_02042.png', 'dataset/trainset/non-faces/B20_01519.png', 'dataset/trainset/non-faces/B20_01914.png', 'dataset/trainset/non-faces/B5_00092.png', 'dataset/trainset/non-faces/B20_02427.png', 'dataset/trainset/non-faces/B1_00012.png', 'dataset/trainset/non-faces/B20_01865.png', 'dataset/trainset/non-faces/B5_00070.png', 'dataset/trainset/non-faces/B1_00333.png', 'dataset/trainset/non-faces/B20_02284.png', 'dataset/trainset/non-faces/B20_02266.png', 'dataset/trainset/non-faces/B1_00430.png', 'dataset/trainset/non-faces/B1_00061.png', 'dataset/trainset/non-faces/B20_01703.png', 'dataset/trainset/non-faces/B1_00363.png', 'dataset/trainset/non-faces/B20_01577.png', 'dataset/trainset/non-faces/B20_01684.png', 'dataset/trainset/non-faces/B20_02097.png', 'dataset/trainset/non-faces/B1_00272.png', 'dataset/trainset/non-faces/B1_00431.png', 'dataset/trainset/non-faces/B1_00556.png', 'dataset/trainset/non-faces/B1_00144.png', 'dataset/trainset/non-faces/B20_02111.png', 'dataset/trainset/non-faces/B1_00119.png', 'dataset/trainset/non-faces/B20_01701.png', 'dataset/trainset/non-faces/B5_00121.png', 'dataset/trainset/non-faces/B20_01828.png', 'dataset/trainset/non-faces/B20_02492.png', 'dataset/trainset/non-faces/B1_00301.png', 'dataset/trainset/non-faces/B5_00219.png', 'dataset/trainset/non-faces/B20_02539.png', 'dataset/trainset/non-faces/B20_01647.png', 'dataset/trainset/non-faces/B20_02432.png', 'dataset/trainset/non-faces/B20_01887.png', 'dataset/trainset/non-faces/B1_00548.png', 'dataset/trainset/non-faces/B1_00491.png', 'dataset/trainset/non-faces/B5_00226.png', 'dataset/trainset/non-faces/B20_01520.png', 'dataset/trainset/non-faces/B20_02328.png', 'dataset/trainset/non-faces/B20_02175.png', 'dataset/trainset/non-faces/B1_00066.png', 'dataset/trainset/non-faces/B1_00107.png', 'dataset/trainset/non-faces/B20_01777.png', 'dataset/trainset/non-faces/B1_00352.png', 'dataset/trainset/non-faces/B20_01512.png', 'dataset/trainset/non-faces/B20_01709.png', 'dataset/trainset/non-faces/B20_02038.png', 'dataset/trainset/non-faces/B20_01820.png', 'dataset/trainset/non-faces/B1_00242.png', 'dataset/trainset/non-faces/B20_01678.png', 'dataset/trainset/non-faces/B20_02527.png', 'dataset/trainset/non-faces/B20_02066.png', 'dataset/trainset/non-faces/B20_01891.png', 'dataset/trainset/non-faces/B20_01995.png', 'dataset/trainset/non-faces/B20_02293.png', 'dataset/trainset/non-faces/B5_00002.png', 'dataset/trainset/non-faces/B20_01516.png', 'dataset/trainset/non-faces/B1_00495.png', 'dataset/trainset/non-faces/B20_02043.png', 'dataset/trainset/non-faces/B5_00246.png', 'dataset/trainset/non-faces/B20_01897.png', 'dataset/trainset/non-faces/B20_02247.png', 'dataset/trainset/non-faces/B1_00155.png', 'dataset/trainset/non-faces/B20_01745.png', 'dataset/trainset/non-faces/B20_02588.png', 'dataset/trainset/non-faces/B20_02268.png', 'dataset/trainset/non-faces/B20_01823.png', 'dataset/trainset/non-faces/B5_00332.png', 'dataset/trainset/non-faces/B5_00184.png', 'dataset/trainset/non-faces/B20_01748.png', 'dataset/trainset/non-faces/B1_00168.png', 'dataset/trainset/non-faces/B1_00425.png', 'dataset/trainset/non-faces/B20_01530.png', 'dataset/trainset/non-faces/B5_00068.png', 'dataset/trainset/non-faces/B1_00450.png', 'dataset/trainset/non-faces/B20_01886.png', 'dataset/trainset/non-faces/B5_00147.png', 'dataset/trainset/non-faces/B20_02485.png', 'dataset/trainset/non-faces/B20_01989.png', 'dataset/trainset/non-faces/B20_02434.png', 'dataset/trainset/non-faces/B20_01901.png', 'dataset/trainset/non-faces/B1_00276.png', 'dataset/trainset/non-faces/B20_02585.png', 'dataset/trainset/non-faces/B5_00302.png', 'dataset/trainset/non-faces/B5_00225.png', 'dataset/trainset/non-faces/B1_00289.png', 'dataset/trainset/non-faces/B1_00380.png', 'dataset/trainset/non-faces/B1_00469.png', 'dataset/trainset/non-faces/B5_00066.png', 'dataset/trainset/non-faces/B20_02494.png', 'dataset/trainset/non-faces/B20_02204.png', 'dataset/trainset/non-faces/B20_02288.png', 'dataset/trainset/non-faces/B20_02278.png', 'dataset/trainset/non-faces/B20_02259.png', 'dataset/trainset/non-faces/B20_01870.png', 'dataset/trainset/non-faces/B20_01787.png', 'dataset/trainset/non-faces/B20_02460.png', 'dataset/trainset/non-faces/B5_00273.png', 'dataset/trainset/non-faces/B1_00490.png', 'dataset/trainset/non-faces/B20_01690.png', 'dataset/trainset/non-faces/B20_02282.png', 'dataset/trainset/non-faces/B5_00090.png', 'dataset/trainset/non-faces/B5_00064.png', 'dataset/trainset/non-faces/B20_02423.png', 'dataset/trainset/non-faces/B20_01628.png', 'dataset/trainset/non-faces/B20_01832.png', 'dataset/trainset/non-faces/B5_00280.png', 'dataset/trainset/non-faces/B1_00427.png', 'dataset/trainset/non-faces/B20_01742.png', 'dataset/trainset/non-faces/B20_01708.png', 'dataset/trainset/non-faces/B5_00159.png', 'dataset/trainset/non-faces/B5_00001.png', 'dataset/trainset/non-faces/B20_01848.png', 'dataset/trainset/non-faces/B20_01990.png', 'dataset/trainset/non-faces/B20_02535.png', 'dataset/trainset/non-faces/B20_01571.png', 'dataset/trainset/non-faces/B5_00151.png', 'dataset/trainset/non-faces/B20_02029.png', 'dataset/trainset/non-faces/B1_00321.png', 'dataset/trainset/non-faces/B20_01822.png', 'dataset/trainset/non-faces/B1_00304.png', 'dataset/trainset/non-faces/B20_01559.png', 'dataset/trainset/non-faces/B20_02373.png', 'dataset/trainset/non-faces/B20_02217.png', 'dataset/trainset/non-faces/B5_00069.png', 'dataset/trainset/non-faces/B1_00218.png', 'dataset/trainset/non-faces/B20_02273.png', 'dataset/trainset/non-faces/B20_01692.png', 'dataset/trainset/non-faces/B20_02499.png', 'dataset/trainset/non-faces/B20_01638.png', 'dataset/trainset/non-faces/B20_02243.png', 'dataset/trainset/non-faces/B20_01797.png', 'dataset/trainset/non-faces/B5_00035.png', 'dataset/trainset/non-faces/B20_01789.png', 'dataset/trainset/non-faces/B5_00247.png', 'dataset/trainset/non-faces/B20_01574.png', 'dataset/trainset/non-faces/B1_00263.png', 'dataset/trainset/non-faces/B1_00302.png', 'dataset/trainset/non-faces/B20_02108.png', 'dataset/trainset/non-faces/B20_01649.png', 'dataset/trainset/non-faces/B20_02389.png', 'dataset/trainset/non-faces/B20_02176.png', 'dataset/trainset/non-faces/B1_00501.png', 'dataset/trainset/non-faces/B5_00087.png', 'dataset/trainset/non-faces/B1_00329.png', 'dataset/trainset/non-faces/B1_00447.png', 'dataset/trainset/non-faces/B20_01544.png', 'dataset/trainset/non-faces/B20_01592.png', 'dataset/trainset/non-faces/B20_02013.png', 'dataset/trainset/non-faces/B20_02045.png', 'dataset/trainset/non-faces/B1_00224.png', 'dataset/trainset/non-faces/B1_00404.png', 'dataset/trainset/non-faces/B20_02014.png', 'dataset/trainset/non-faces/B5_00198.png', 'dataset/trainset/non-faces/B20_02324.png', 'dataset/trainset/non-faces/B1_00492.png', 'dataset/trainset/non-faces/B20_02578.png', 'dataset/trainset/non-faces/B20_02344.png', 'dataset/trainset/non-faces/B1_00395.png', 'dataset/trainset/non-faces/B5_00196.png', 'dataset/trainset/non-faces/B20_02035.png', 'dataset/trainset/non-faces/B20_02545.png', 'dataset/trainset/non-faces/B1_00271.png', 'dataset/trainset/non-faces/B20_02579.png', 'dataset/trainset/non-faces/B1_00241.png', 'dataset/trainset/non-faces/B1_00448.png', 'dataset/trainset/non-faces/B20_01961.png', 'dataset/trainset/non-faces/B20_02287.png', 'dataset/trainset/non-faces/B20_02358.png', 'dataset/trainset/non-faces/B20_02131.png', 'dataset/trainset/non-faces/B1_00034.png', 'dataset/trainset/non-faces/B20_01540.png', 'dataset/trainset/non-faces/B20_01607.png', 'dataset/trainset/non-faces/B5_00022.png', 'dataset/trainset/non-faces/B20_02137.png', 'dataset/trainset/non-faces/B20_01699.png', 'dataset/trainset/non-faces/B20_01799.png', 'dataset/trainset/non-faces/B20_01603.png', 'dataset/trainset/non-faces/B20_01754.png', 'dataset/trainset/non-faces/B20_01759.png', 'dataset/trainset/non-faces/B20_02115.png', 'dataset/trainset/non-faces/B5_00303.png', 'dataset/trainset/non-faces/B20_02260.png', 'dataset/trainset/non-faces/B20_01867.png', 'dataset/trainset/non-faces/B5_00270.png', 'dataset/trainset/non-faces/B1_00442.png', 'dataset/trainset/non-faces/B20_02464.png', 'dataset/trainset/non-faces/B20_01604.png', 'dataset/trainset/non-faces/B20_02601.png', 'dataset/trainset/non-faces/B5_00055.png', 'dataset/trainset/non-faces/B20_02471.png', 'dataset/trainset/non-faces/B5_00115.png', 'dataset/trainset/non-faces/B20_02341.png', 'dataset/trainset/non-faces/B20_01738.png', 'dataset/trainset/non-faces/B1_00121.png', 'dataset/trainset/non-faces/B20_02254.png', 'dataset/trainset/non-faces/B20_01693.png', 'dataset/trainset/non-faces/B1_00149.png', 'dataset/trainset/non-faces/B1_00451.png', 'dataset/trainset/non-faces/B20_02569.png', 'dataset/trainset/non-faces/B1_00520.png', 'dataset/trainset/non-faces/B5_00312.png', 'dataset/trainset/non-faces/B20_01970.png', 'dataset/trainset/non-faces/B20_02116.png', 'dataset/trainset/non-faces/B5_00019.png', 'dataset/trainset/non-faces/B20_02231.png', 'dataset/trainset/non-faces/B20_02418.png', 'dataset/trainset/non-faces/B20_01803.png', 'dataset/trainset/non-faces/B20_01840.png', 'dataset/trainset/non-faces/B20_02183.png', 'dataset/trainset/non-faces/B1_00179.png', 'dataset/trainset/non-faces/B20_02080.png', 'dataset/trainset/non-faces/B1_00284.png', 'dataset/trainset/non-faces/B1_00067.png', 'dataset/trainset/non-faces/B20_01668.png', 'dataset/trainset/non-faces/B20_02236.png', 'dataset/trainset/non-faces/B1_00082.png', 'dataset/trainset/non-faces/B20_01931.png', 'dataset/trainset/non-faces/B1_00123.png', 'dataset/trainset/non-faces/B1_00285.png', 'dataset/trainset/non-faces/B20_01771.png', 'dataset/trainset/non-faces/B1_00039.png', 'dataset/trainset/non-faces/B20_02397.png', 'dataset/trainset/non-faces/B1_00228.png', 'dataset/trainset/non-faces/B1_00024.png', 'dataset/trainset/non-faces/B20_02299.png', 'dataset/trainset/non-faces/B1_00226.png', 'dataset/trainset/non-faces/B20_02087.png', 'dataset/trainset/non-faces/B5_00032.png', 'dataset/trainset/non-faces/B20_01629.png', 'dataset/trainset/non-faces/B20_01916.png', 'dataset/trainset/non-faces/B20_02516.png', 'dataset/trainset/non-faces/B20_02016.png', 'dataset/trainset/non-faces/B20_02354.png', 'dataset/trainset/non-faces/B5_00291.png', 'dataset/trainset/non-faces/B20_02084.png', 'dataset/trainset/non-faces/B1_00055.png', 'dataset/trainset/non-faces/B5_00252.png', 'dataset/trainset/non-faces/B20_01903.png', 'dataset/trainset/non-faces/B5_00177.png', 'dataset/trainset/non-faces/B1_00295.png', 'dataset/trainset/non-faces/B20_02179.png', 'dataset/trainset/non-faces/B20_02568.png', 'dataset/trainset/non-faces/B20_01756.png', 'dataset/trainset/non-faces/B1_00212.png', 'dataset/trainset/non-faces/B5_00058.png', 'dataset/trainset/non-faces/B20_01575.png', 'dataset/trainset/non-faces/B20_01723.png', 'dataset/trainset/non-faces/B20_01552.png', 'dataset/trainset/non-faces/B20_02192.png', 'dataset/trainset/non-faces/B5_00340.png', 'dataset/trainset/non-faces/B20_02021.png', 'dataset/trainset/non-faces/B5_00062.png', 'dataset/trainset/non-faces/B1_00134.png', 'dataset/trainset/non-faces/B1_00377.png', 'dataset/trainset/non-faces/B5_00119.png', 'dataset/trainset/non-faces/B5_00031.png', 'dataset/trainset/non-faces/B5_00048.png', 'dataset/trainset/non-faces/B5_00234.png', 'dataset/trainset/non-faces/B5_00028.png', 'dataset/trainset/non-faces/B1_00086.png', 'dataset/trainset/non-faces/B20_02122.png', 'dataset/trainset/non-faces/B20_01977.png', 'dataset/trainset/non-faces/B20_01780.png', 'dataset/trainset/non-faces/B1_00038.png', 'dataset/trainset/non-faces/B1_00328.png', 'dataset/trainset/non-faces/B1_00388.png', 'dataset/trainset/non-faces/B5_00257.png', 'dataset/trainset/non-faces/B20_02135.png', 'dataset/trainset/non-faces/B20_01726.png', 'dataset/trainset/non-faces/B20_02085.png', 'dataset/trainset/non-faces/B20_02222.png', 'dataset/trainset/non-faces/B1_00341.png', 'dataset/trainset/non-faces/B5_00256.png', 'dataset/trainset/non-faces/B20_01770.png', 'dataset/trainset/non-faces/B20_01975.png', 'dataset/trainset/non-faces/B1_00456.png', 'dataset/trainset/non-faces/B20_02162.png', 'dataset/trainset/non-faces/B20_02054.png', 'dataset/trainset/non-faces/B20_01758.png', 'dataset/trainset/non-faces/B20_01819.png', 'dataset/trainset/non-faces/B20_02472.png', 'dataset/trainset/non-faces/B20_01825.png', 'dataset/trainset/non-faces/B1_00394.png', 'dataset/trainset/non-faces/B1_00474.png', 'dataset/trainset/non-faces/B1_00312.png', 'dataset/trainset/non-faces/B5_00277.png', 'dataset/trainset/non-faces/B1_00344.png', 'dataset/trainset/non-faces/B20_02216.png', 'dataset/trainset/non-faces/B1_00357.png', 'dataset/trainset/non-faces/B20_01593.png', 'dataset/trainset/non-faces/B1_00186.png', 'dataset/trainset/non-faces/B1_00349.png', 'dataset/trainset/non-faces/B20_02542.png', 'dataset/trainset/non-faces/B1_00096.png', 'dataset/trainset/non-faces/B1_00152.png', 'dataset/trainset/non-faces/B20_02576.png', 'dataset/trainset/non-faces/B20_02557.png', 'dataset/trainset/non-faces/B1_00282.png', 'dataset/trainset/non-faces/B20_01946.png', 'dataset/trainset/non-faces/B20_02501.png', 'dataset/trainset/non-faces/B1_00303.png', 'dataset/trainset/non-faces/B20_01696.png', 'dataset/trainset/non-faces/B20_02458.png', 'dataset/trainset/non-faces/B20_01947.png', 'dataset/trainset/non-faces/B20_01928.png', 'dataset/trainset/non-faces/B1_00411.png', 'dataset/trainset/non-faces/B5_00264.png', 'dataset/trainset/non-faces/B1_00300.png', 'dataset/trainset/non-faces/B20_02465.png', 'dataset/trainset/non-faces/B5_00304.png', 'dataset/trainset/non-faces/B20_01906.png', 'dataset/trainset/non-faces/B1_00030.png', 'dataset/trainset/non-faces/B1_00546.png', 'dataset/trainset/non-faces/B20_01852.png', 'dataset/trainset/non-faces/B20_01763.png', 'dataset/trainset/non-faces/B1_00104.png', 'dataset/trainset/non-faces/B20_02072.png', 'dataset/trainset/non-faces/B20_01568.png', 'dataset/trainset/non-faces/B20_01509.png', 'dataset/trainset/non-faces/B1_00256.png', 'dataset/trainset/non-faces/B20_02547.png', 'dataset/trainset/non-faces/B5_00024.png', 'dataset/trainset/non-faces/B1_00159.png', 'dataset/trainset/non-faces/B20_02120.png', 'dataset/trainset/non-faces/B20_02421.png', 'dataset/trainset/non-faces/B5_00279.png', 'dataset/trainset/non-faces/B20_01641.png', 'dataset/trainset/non-faces/B1_00217.png', 'dataset/trainset/non-faces/B1_00531.png', 'dataset/trainset/non-faces/B5_00149.png', 'dataset/trainset/non-faces/B20_02551.png', 'dataset/trainset/non-faces/B1_00070.png', 'dataset/trainset/non-faces/B20_02605.png', 'dataset/trainset/non-faces/B5_00078.png', 'dataset/trainset/non-faces/B20_02495.png', 'dataset/trainset/non-faces/B5_00172.png', 'dataset/trainset/non-faces/B1_00093.png', 'dataset/trainset/non-faces/B20_02193.png', 'dataset/trainset/non-faces/B1_00177.png', 'dataset/trainset/non-faces/B5_00141.png', 'dataset/trainset/non-faces/B20_01614.png', 'dataset/trainset/non-faces/B5_00086.png', 'dataset/trainset/non-faces/B5_00195.png', 'dataset/trainset/non-faces/B5_00161.png', 'dataset/trainset/non-faces/B5_00228.png', 'dataset/trainset/non-faces/B20_01814.png', 'dataset/trainset/non-faces/B20_02469.png', 'dataset/trainset/non-faces/B1_00036.png', 'dataset/trainset/non-faces/B20_01907.png', 'dataset/trainset/non-faces/B1_00373.png', 'dataset/trainset/non-faces/B20_01752.png', 'dataset/trainset/non-faces/B5_00000.png', 'dataset/trainset/non-faces/B20_02059.png', 'dataset/trainset/non-faces/B1_00264.png', 'dataset/trainset/non-faces/B20_02363.png', 'dataset/trainset/non-faces/B20_01981.png', 'dataset/trainset/non-faces/B5_00285.png', 'dataset/trainset/non-faces/B20_02200.png', 'dataset/trainset/non-faces/B1_00261.png', 'dataset/trainset/non-faces/B1_00524.png', 'dataset/trainset/non-faces/B1_00466.png', 'dataset/trainset/non-faces/B20_01837.png', 'dataset/trainset/non-faces/B20_02556.png', 'dataset/trainset/non-faces/B20_02223.png', 'dataset/trainset/non-faces/B20_02496.png', 'dataset/trainset/non-faces/B1_00167.png', 'dataset/trainset/non-faces/B20_02505.png', 'dataset/trainset/non-faces/B20_02346.png', 'dataset/trainset/non-faces/B5_00313.png', 'dataset/trainset/non-faces/B1_00026.png', 'dataset/trainset/non-faces/B20_02052.png', 'dataset/trainset/non-faces/B20_01660.png', 'dataset/trainset/non-faces/B1_00158.png', 'dataset/trainset/non-faces/B20_01960.png', 'dataset/trainset/non-faces/B1_00449.png', 'dataset/trainset/non-faces/B5_00286.png', 'dataset/trainset/non-faces/B1_00077.png', 'dataset/trainset/non-faces/B5_00168.png', 'dataset/trainset/non-faces/B20_01729.png', 'dataset/trainset/non-faces/B20_02487.png', 'dataset/trainset/non-faces/B20_01957.png', 'dataset/trainset/non-faces/B5_00204.png', 'dataset/trainset/non-faces/B1_00277.png', 'dataset/trainset/non-faces/B20_01581.png', 'dataset/trainset/non-faces/B5_00170.png', 'dataset/trainset/non-faces/B20_01769.png', 'dataset/trainset/non-faces/B20_02459.png', 'dataset/trainset/non-faces/B1_00476.png', 'dataset/trainset/non-faces/B20_01861.png', 'dataset/trainset/non-faces/B20_02403.png', 'dataset/trainset/non-faces/B20_01712.png', 'dataset/trainset/non-faces/B1_00079.png', 'dataset/trainset/non-faces/B1_00315.png', 'dataset/trainset/non-faces/B20_02447.png', 'dataset/trainset/non-faces/B20_02285.png', 'dataset/trainset/non-faces/B20_01973.png', 'dataset/trainset/non-faces/B5_00305.png', 'dataset/trainset/non-faces/B1_00443.png', 'dataset/trainset/non-faces/B5_00253.png', 'dataset/trainset/non-faces/B20_02234.png', 'dataset/trainset/non-faces/B20_02071.png', 'dataset/trainset/non-faces/B1_00103.png', 'dataset/trainset/non-faces/B1_00078.png', 'dataset/trainset/non-faces/B20_02367.png', 'dataset/trainset/non-faces/B20_02269.png', 'dataset/trainset/non-faces/B20_02463.png', 'dataset/trainset/non-faces/B5_00004.png', 'dataset/trainset/non-faces/B20_01843.png', 'dataset/trainset/non-faces/B1_00270.png', 'dataset/trainset/non-faces/B1_00129.png', 'dataset/trainset/non-faces/B20_01507.png', 'dataset/trainset/non-faces/B20_02145.png', 'dataset/trainset/non-faces/B1_00208.png', 'dataset/trainset/non-faces/B20_01851.png', 'dataset/trainset/non-faces/B1_00499.png', 'dataset/trainset/non-faces/B20_02091.png', 'dataset/trainset/non-faces/B1_00488.png', 'dataset/trainset/non-faces/B20_02275.png', 'dataset/trainset/non-faces/B20_02450.png', 'dataset/trainset/non-faces/B1_00052.png', 'dataset/trainset/non-faces/B5_00289.png', 'dataset/trainset/non-faces/B5_00326.png', 'dataset/trainset/non-faces/B5_00251.png', 'dataset/trainset/non-faces/B20_02543.png', 'dataset/trainset/non-faces/B20_02300.png', 'dataset/trainset/non-faces/B20_01549.png', 'dataset/trainset/non-faces/B5_00056.png', 'dataset/trainset/non-faces/B20_02148.png', 'dataset/trainset/non-faces/B5_00319.png', 'dataset/trainset/non-faces/B20_01542.png', 'dataset/trainset/non-faces/B1_00071.png', 'dataset/trainset/non-faces/B20_01798.png', 'dataset/trainset/non-faces/B20_01537.png', 'dataset/trainset/non-faces/B1_00136.png', 'dataset/trainset/non-faces/B20_02060.png', 'dataset/trainset/non-faces/B20_01956.png', 'dataset/trainset/non-faces/B20_01657.png', 'dataset/trainset/non-faces/B20_01567.png', 'dataset/trainset/non-faces/B20_02382.png', 'dataset/trainset/non-faces/B20_02385.png', 'dataset/trainset/non-faces/B20_01951.png', 'dataset/trainset/non-faces/B20_02490.png', 'dataset/trainset/non-faces/B20_01644.png', 'dataset/trainset/non-faces/B20_01874.png', 'dataset/trainset/non-faces/B1_00138.png', 'dataset/trainset/non-faces/B5_00207.png', 'dataset/trainset/non-faces/B20_01597.png', 'dataset/trainset/non-faces/B20_01858.png', 'dataset/trainset/non-faces/B20_01818.png', 'dataset/trainset/non-faces/B1_00259.png', 'dataset/trainset/non-faces/B5_00278.png', 'dataset/trainset/non-faces/B1_00544.png', 'dataset/trainset/non-faces/B20_02390.png', 'dataset/trainset/non-faces/B20_01862.png', 'dataset/trainset/non-faces/B20_01727.png', 'dataset/trainset/non-faces/B1_00247.png', 'dataset/trainset/non-faces/B5_00217.png', 'dataset/trainset/non-faces/B5_00236.png', 'dataset/trainset/non-faces/B5_00333.png', 'dataset/trainset/non-faces/B5_00189.png', 'dataset/trainset/non-faces/B1_00311.png', 'dataset/trainset/non-faces/B5_00296.png', 'dataset/trainset/non-faces/B1_00478.png', 'dataset/trainset/non-faces/B20_02345.png', 'dataset/trainset/non-faces/B20_01534.png', 'dataset/trainset/non-faces/B20_02461.png', 'dataset/trainset/non-faces/B20_02340.png', 'dataset/trainset/non-faces/B1_00020.png', 'dataset/trainset/non-faces/B1_00126.png', 'dataset/trainset/non-faces/B1_00379.png', 'dataset/trainset/non-faces/B1_00225.png', 'dataset/trainset/non-faces/B5_00052.png', 'dataset/trainset/non-faces/B20_02141.png', 'dataset/trainset/non-faces/B20_01826.png', 'dataset/trainset/non-faces/B20_02541.png', 'dataset/trainset/non-faces/B20_02503.png', 'dataset/trainset/non-faces/B5_00060.png', 'dataset/trainset/non-faces/B20_02533.png', 'dataset/trainset/non-faces/B20_02307.png', 'dataset/trainset/non-faces/B1_00098.png', 'dataset/trainset/non-faces/B20_02528.png', 'dataset/trainset/non-faces/B1_00356.png', 'dataset/trainset/non-faces/B5_00093.png', 'dataset/trainset/non-faces/B1_00154.png', 'dataset/trainset/non-faces/B1_00308.png', 'dataset/trainset/non-faces/B5_00116.png', 'dataset/trainset/non-faces/B20_02517.png', 'dataset/trainset/non-faces/B20_02391.png', 'dataset/trainset/non-faces/B5_00102.png', 'dataset/trainset/non-faces/B20_02424.png', 'dataset/trainset/non-faces/B1_00019.png', 'dataset/trainset/non-faces/B20_02082.png', 'dataset/trainset/non-faces/B20_02018.png', 'dataset/trainset/non-faces/B20_02513.png', 'dataset/trainset/non-faces/B5_00012.png', 'dataset/trainset/non-faces/B20_02453.png', 'dataset/trainset/non-faces/B1_00504.png', 'dataset/trainset/non-faces/B20_02258.png', 'dataset/trainset/non-faces/B20_02481.png', 'dataset/trainset/non-faces/B1_00120.png', 'dataset/trainset/non-faces/B1_00108.png', 'dataset/trainset/non-faces/B1_00245.png', 'dataset/trainset/non-faces/B20_01683.png', 'dataset/trainset/non-faces/B1_00515.png', 'dataset/trainset/non-faces/B1_00428.png', 'dataset/trainset/non-faces/B1_00278.png', 'dataset/trainset/non-faces/B1_00210.png', 'dataset/trainset/non-faces/B1_00489.png', 'dataset/trainset/non-faces/B20_01594.png', 'dataset/trainset/non-faces/B20_02020.png', 'dataset/trainset/non-faces/B20_02159.png', 'dataset/trainset/non-faces/B20_01923.png', 'dataset/trainset/non-faces/B1_00389.png', 'dataset/trainset/non-faces/B1_00475.png', 'dataset/trainset/non-faces/B20_01664.png', 'dataset/trainset/non-faces/B20_02203.png', 'dataset/trainset/non-faces/B20_01734.png', 'dataset/trainset/non-faces/B1_00008.png', 'dataset/trainset/non-faces/B20_01648.png', 'dataset/trainset/non-faces/B20_01918.png', 'dataset/trainset/non-faces/B20_02570.png', 'dataset/trainset/non-faces/B20_01808.png', 'dataset/trainset/non-faces/B20_01673.png', 'dataset/trainset/non-faces/B1_00537.png', 'dataset/trainset/non-faces/B5_00173.png', 'dataset/trainset/non-faces/B20_02143.png', 'dataset/trainset/non-faces/B20_02553.png', 'dataset/trainset/non-faces/B20_01728.png', 'dataset/trainset/non-faces/B20_02381.png', 'dataset/trainset/non-faces/B5_00307.png', 'dataset/trainset/non-faces/B5_00006.png', 'dataset/trainset/non-faces/B20_02124.png', 'dataset/trainset/non-faces/B5_00282.png', 'dataset/trainset/non-faces/B20_02178.png', 'dataset/trainset/non-faces/B20_02238.png', 'dataset/trainset/non-faces/B5_00203.png', 'dataset/trainset/non-faces/B20_01536.png', 'dataset/trainset/non-faces/B20_02219.png', 'dataset/trainset/non-faces/B20_02051.png', 'dataset/trainset/non-faces/B1_00397.png', 'dataset/trainset/non-faces/B1_00040.png', 'dataset/trainset/non-faces/B20_01863.png', 'dataset/trainset/non-faces/B5_00072.png', 'dataset/trainset/non-faces/B5_00146.png', 'dataset/trainset/non-faces/B20_02399.png', 'dataset/trainset/non-faces/B5_00221.png', 'dataset/trainset/non-faces/B1_00286.png', 'dataset/trainset/non-faces/B20_01766.png', 'dataset/trainset/non-faces/B20_02134.png', 'dataset/trainset/non-faces/B20_02512.png', 'dataset/trainset/non-faces/B20_02448.png', 'dataset/trainset/non-faces/B20_02554.png', 'dataset/trainset/non-faces/B5_00266.png', 'dataset/trainset/non-faces/B5_00320.png', 'dataset/trainset/non-faces/B20_02377.png', 'dataset/trainset/non-faces/B5_00287.png', 'dataset/trainset/non-faces/B1_00526.png', 'dataset/trainset/non-faces/B5_00134.png', 'dataset/trainset/non-faces/B1_00390.png', 'dataset/trainset/non-faces/B20_02376.png', 'dataset/trainset/non-faces/B1_00324.png', 'dataset/trainset/non-faces/B20_02479.png', 'dataset/trainset/non-faces/B20_02409.png', 'dataset/trainset/non-faces/B20_02295.png', 'dataset/trainset/non-faces/B20_01857.png', 'dataset/trainset/non-faces/B20_02321.png', 'dataset/trainset/non-faces/B20_01674.png', 'dataset/trainset/non-faces/B20_01846.png', 'dataset/trainset/non-faces/B20_01570.png', 'dataset/trainset/non-faces/B20_01821.png', 'dataset/trainset/non-faces/B20_02436.png', 'dataset/trainset/non-faces/B20_02435.png', 'dataset/trainset/non-faces/B5_00038.png', 'dataset/trainset/non-faces/B20_01929.png', 'dataset/trainset/non-faces/B1_00521.png', 'dataset/trainset/non-faces/B1_00417.png', 'dataset/trainset/non-faces/B1_00374.png', 'dataset/trainset/non-faces/B1_00340.png', 'dataset/trainset/non-faces/B5_00135.png', 'dataset/trainset/non-faces/B1_00287.png', 'dataset/trainset/non-faces/B20_02311.png', 'dataset/trainset/non-faces/B20_01697.png', 'dataset/trainset/non-faces/B20_02229.png', 'dataset/trainset/non-faces/B1_00454.png', 'dataset/trainset/non-faces/B20_02031.png', 'dataset/trainset/non-faces/B1_00172.png', 'dataset/trainset/non-faces/B5_00104.png', 'dataset/trainset/non-faces/B20_01686.png', 'dataset/trainset/non-faces/B20_01950.png', 'dataset/trainset/non-faces/B20_02347.png', 'dataset/trainset/non-faces/B5_00238.png', 'dataset/trainset/non-faces/B5_00335.png', 'dataset/trainset/non-faces/B1_00246.png', 'dataset/trainset/non-faces/B20_01532.png', 'dataset/trainset/non-faces/B1_00182.png', 'dataset/trainset/non-faces/B1_00441.png', 'dataset/trainset/non-faces/B1_00398.png', 'dataset/trainset/non-faces/B20_02276.png', 'dataset/trainset/non-faces/B20_01665.png', 'dataset/trainset/non-faces/B1_00331.png', 'dataset/trainset/non-faces/B5_00179.png', 'dataset/trainset/non-faces/B20_01602.png', 'dataset/trainset/non-faces/B20_02023.png', 'dataset/trainset/non-faces/B5_00337.png', 'dataset/trainset/non-faces/B20_02205.png', 'dataset/trainset/non-faces/B20_02480.png', 'dataset/trainset/non-faces/B1_00201.png', 'dataset/trainset/non-faces/B5_00123.png', 'dataset/trainset/non-faces/B5_00205.png', 'dataset/trainset/non-faces/B20_02422.png', 'dataset/trainset/non-faces/B20_02462.png', 'dataset/trainset/non-faces/B20_01773.png', 'dataset/trainset/non-faces/B5_00160.png', 'dataset/trainset/non-faces/B5_00166.png', 'dataset/trainset/non-faces/B5_00334.png', 'dataset/trainset/non-faces/B20_01637.png', 'dataset/trainset/non-faces/B5_00293.png', 'dataset/trainset/non-faces/B20_02370.png', 'dataset/trainset/non-faces/B1_00407.png', 'dataset/trainset/non-faces/B1_00462.png', 'dataset/trainset/non-faces/B20_01585.png', 'dataset/trainset/non-faces/B1_00359.png', 'dataset/trainset/non-faces/B20_01578.png', 'dataset/trainset/non-faces/B20_02039.png', 'dataset/trainset/non-faces/B20_01801.png', 'dataset/trainset/non-faces/B20_02353.png', 'dataset/trainset/non-faces/B1_00402.png', 'dataset/trainset/non-faces/B1_00045.png', 'dataset/trainset/non-faces/B20_01538.png', 'dataset/trainset/non-faces/B5_00011.png', 'dataset/trainset/non-faces/B5_00042.png', 'dataset/trainset/non-faces/B20_02343.png', 'dataset/trainset/non-faces/B20_01749.png', 'dataset/trainset/non-faces/B5_00193.png', 'dataset/trainset/non-faces/B20_01985.png', 'dataset/trainset/non-faces/B20_01675.png', 'dataset/trainset/non-faces/B20_02339.png', 'dataset/trainset/non-faces/B20_01715.png', 'dataset/trainset/non-faces/B1_00230.png', 'dataset/trainset/non-faces/B5_00176.png', 'dataset/trainset/non-faces/B20_02544.png', 'dataset/trainset/non-faces/B20_02594.png', 'dataset/trainset/non-faces/B1_00419.png', 'dataset/trainset/non-faces/B20_02197.png', 'dataset/trainset/non-faces/B1_00480.png', 'dataset/trainset/non-faces/B1_00041.png', 'dataset/trainset/non-faces/B20_01556.png', 'dataset/trainset/non-faces/B1_00552.png', 'dataset/trainset/non-faces/B20_02218.png', 'dataset/trainset/non-faces/B1_00434.png', 'dataset/trainset/non-faces/B20_01968.png', 'dataset/trainset/non-faces/B5_00324.png', 'dataset/trainset/non-faces/B20_02507.png', 'dataset/trainset/non-faces/B20_02575.png', 'dataset/trainset/non-faces/B20_02257.png', 'dataset/trainset/non-faces/B1_00056.png', 'dataset/trainset/non-faces/B1_00360.png', 'dataset/trainset/non-faces/B1_00291.png', 'dataset/trainset/non-faces/B1_00381.png', 'dataset/trainset/non-faces/B20_01786.png', 'dataset/trainset/non-faces/B20_02537.png', 'dataset/trainset/non-faces/B20_02587.png', 'dataset/trainset/non-faces/B1_00237.png', 'dataset/trainset/non-faces/B5_00156.png', 'dataset/trainset/non-faces/B20_02017.png', 'dataset/trainset/non-faces/B5_00201.png', 'dataset/trainset/non-faces/B20_01631.png', 'dataset/trainset/non-faces/B20_01795.png', 'dataset/trainset/non-faces/B20_01563.png', 'dataset/trainset/non-faces/B5_00021.png', 'dataset/trainset/non-faces/B20_02196.png', 'dataset/trainset/non-faces/B1_00413.png', 'dataset/trainset/non-faces/B5_00061.png', 'dataset/trainset/non-faces/B1_00140.png', 'dataset/trainset/non-faces/B1_00190.png', 'dataset/trainset/non-faces/B20_01526.png', 'dataset/trainset/non-faces/B20_01689.png', 'dataset/trainset/non-faces/B1_00141.png', 'dataset/trainset/non-faces/B5_00095.png', 'dataset/trainset/non-faces/B1_00438.png', 'dataset/trainset/non-faces/B1_00279.png', 'dataset/trainset/non-faces/B1_00457.png', 'dataset/trainset/non-faces/B1_00127.png', 'dataset/trainset/non-faces/B5_00145.png', 'dataset/trainset/non-faces/B20_01802.png', 'dataset/trainset/non-faces/B1_00557.png', 'dataset/trainset/non-faces/B20_01775.png', 'dataset/trainset/non-faces/B20_02068.png', 'dataset/trainset/non-faces/B1_00323.png', 'dataset/trainset/non-faces/B1_00386.png', 'dataset/trainset/non-faces/B20_02362.png', 'dataset/trainset/non-faces/B20_02206.png', 'dataset/trainset/non-faces/B1_00244.png', 'dataset/trainset/non-faces/B20_01679.png', 'dataset/trainset/non-faces/B1_00482.png', 'dataset/trainset/non-faces/B20_01524.png', 'dataset/trainset/non-faces/B20_02294.png', 'dataset/trainset/non-faces/B1_00519.png', 'dataset/trainset/non-faces/B20_01908.png', 'dataset/trainset/non-faces/B20_01591.png', 'dataset/trainset/non-faces/B20_01860.png', 'dataset/trainset/non-faces/B20_02509.png', 'dataset/trainset/non-faces/B20_02249.png', 'dataset/trainset/non-faces/B1_00248.png', 'dataset/trainset/non-faces/B1_00197.png', 'dataset/trainset/non-faces/B1_00211.png', 'dataset/trainset/non-faces/B20_02002.png', 'dataset/trainset/non-faces/B20_02088.png', 'dataset/trainset/non-faces/B20_02297.png', 'dataset/trainset/non-faces/B1_00231.png', 'dataset/trainset/non-faces/B5_00274.png', 'dataset/trainset/non-faces/B1_00097.png', 'dataset/trainset/non-faces/B20_01917.png', 'dataset/trainset/non-faces/B20_02429.png', 'dataset/trainset/non-faces/B20_01967.png', 'dataset/trainset/non-faces/B5_00194.png', 'dataset/trainset/non-faces/B20_01926.png', 'dataset/trainset/non-faces/B5_00314.png', 'dataset/trainset/non-faces/B1_00060.png', 'dataset/trainset/non-faces/B5_00308.png', 'dataset/trainset/non-faces/B1_00528.png', 'dataset/trainset/non-faces/B20_02138.png', 'dataset/trainset/non-faces/B20_01612.png', 'dataset/trainset/non-faces/B1_00529.png', 'dataset/trainset/non-faces/B1_00376.png', 'dataset/trainset/non-faces/B20_02580.png', 'dataset/trainset/non-faces/B20_01737.png', 'dataset/trainset/non-faces/B20_01835.png', 'dataset/trainset/non-faces/B1_00468.png', 'dataset/trainset/non-faces/B20_02433.png', 'dataset/trainset/non-faces/B20_01710.png', 'dataset/trainset/non-faces/B20_01704.png', 'dataset/trainset/non-faces/B1_00064.png', 'dataset/trainset/non-faces/B20_01714.png', 'dataset/trainset/non-faces/B1_00268.png', 'dataset/trainset/non-faces/B5_00007.png', 'dataset/trainset/non-faces/B20_02419.png', 'dataset/trainset/non-faces/B1_00335.png', 'dataset/trainset/non-faces/B20_02081.png', 'dataset/trainset/non-faces/B1_00543.png', 'dataset/trainset/non-faces/B1_00044.png', 'dataset/trainset/non-faces/B1_00473.png', 'dataset/trainset/non-faces/B20_02170.png', 'dataset/trainset/non-faces/B20_01944.png', 'dataset/trainset/non-faces/B1_00258.png', 'dataset/trainset/non-faces/B20_02015.png', 'dataset/trainset/non-faces/B1_00471.png', 'dataset/trainset/non-faces/B20_02493.png', 'dataset/trainset/non-faces/B1_00171.png', 'dataset/trainset/non-faces/B1_00192.png', 'dataset/trainset/non-faces/B20_02169.png', 'dataset/trainset/non-faces/B20_01610.png', 'dataset/trainset/non-faces/B20_01869.png', 'dataset/trainset/non-faces/B1_00166.png', 'dataset/trainset/non-faces/B20_02524.png', 'dataset/trainset/non-faces/B5_00014.png', 'dataset/trainset/non-faces/B20_02387.png', 'dataset/trainset/non-faces/B1_00021.png', 'dataset/trainset/non-faces/B1_00405.png', 'dataset/trainset/non-faces/B1_00409.png', 'dataset/trainset/non-faces/B20_01788.png', 'dataset/trainset/non-faces/B5_00150.png', 'dataset/trainset/non-faces/B1_00091.png', 'dataset/trainset/non-faces/B1_00072.png', 'dataset/trainset/non-faces/B20_02011.png', 'dataset/trainset/non-faces/B20_02489.png', 'dataset/trainset/non-faces/B20_02033.png', 'dataset/trainset/non-faces/B1_00029.png', 'dataset/trainset/non-faces/B20_01900.png', 'dataset/trainset/non-faces/B5_00094.png', 'dataset/trainset/non-faces/B1_00539.png', 'dataset/trainset/non-faces/B20_01782.png', 'dataset/trainset/non-faces/B5_00122.png', 'dataset/trainset/non-faces/B5_00162.png', 'dataset/trainset/non-faces/B1_00387.png', 'dataset/trainset/non-faces/B20_01781.png', 'dataset/trainset/non-faces/B5_00108.png', 'dataset/trainset/non-faces/B5_00142.png', 'dataset/trainset/non-faces/B20_02130.png', 'dataset/trainset/non-faces/B20_01717.png', 'dataset/trainset/non-faces/B20_01945.png', 'dataset/trainset/non-faces/B5_00259.png', 'dataset/trainset/non-faces/B20_02032.png', 'dataset/trainset/non-faces/B1_00307.png', 'dataset/trainset/non-faces/B5_00322.png', 'dataset/trainset/non-faces/B5_00071.png', 'dataset/trainset/non-faces/B20_01839.png', 'dataset/trainset/non-faces/B1_00319.png', 'dataset/trainset/non-faces/B5_00323.png', 'dataset/trainset/non-faces/B20_01747.png', 'dataset/trainset/non-faces/B5_00239.png', 'dataset/trainset/non-faces/B20_02365.png', 'dataset/trainset/non-faces/B1_00165.png', 'dataset/trainset/non-faces/B20_02036.png', 'dataset/trainset/non-faces/B20_01666.png', 'dataset/trainset/non-faces/B20_01554.png', 'dataset/trainset/non-faces/B20_01915.png', 'dataset/trainset/non-faces/B1_00080.png', 'dataset/trainset/non-faces/B1_00496.png', 'dataset/trainset/non-faces/B20_01576.png', 'dataset/trainset/non-faces/B5_00118.png', 'dataset/trainset/non-faces/B20_02560.png', 'dataset/trainset/non-faces/B20_01635.png', 'dataset/trainset/non-faces/B1_00033.png', 'dataset/trainset/non-faces/B20_02475.png', 'dataset/trainset/non-faces/B20_01943.png', 'dataset/trainset/non-faces/B20_02272.png', 'dataset/trainset/non-faces/B5_00281.png', 'dataset/trainset/non-faces/B20_02467.png', 'dataset/trainset/non-faces/B20_01514.png', 'dataset/trainset/non-faces/B1_00459.png', 'dataset/trainset/non-faces/B5_00131.png', 'dataset/trainset/non-faces/B1_00318.png', 'dataset/trainset/non-faces/B20_02348.png', 'dataset/trainset/non-faces/B20_02100.png']\n"
     ]
    }
   ],
   "source": [
    "train_f = read_files('trainset/faces')\n",
    "train_nf = read_files('trainset/non-faces')\n",
    "print(train_nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBXCQGfS5ntg"
   },
   "source": [
    "### Import TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vp786kAb542v",
    "outputId": "64fa2537-dc5f-43bf-f7ed-84938a0596ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/testset/faces/cmu_0378.png', 'dataset/testset/faces/cmu_0375.png', 'dataset/testset/faces/cmu_0338.png', 'dataset/testset/faces/cmu_0346.png', 'dataset/testset/faces/cmu_0397.png', 'dataset/testset/faces/cmu_0412.png', 'dataset/testset/faces/cmu_0249.png', 'dataset/testset/faces/cmu_0005.png', 'dataset/testset/faces/cmu_0341.png', 'dataset/testset/faces/cmu_0400.png', 'dataset/testset/faces/cmu_0325.png', 'dataset/testset/faces/cmu_0356.png', 'dataset/testset/faces/cmu_0043.png', 'dataset/testset/faces/cmu_0121.png', 'dataset/testset/faces/cmu_0203.png', 'dataset/testset/faces/cmu_0071.png', 'dataset/testset/faces/cmu_0359.png', 'dataset/testset/faces/cmu_0174.png', 'dataset/testset/faces/cmu_0469.png', 'dataset/testset/faces/cmu_0463.png', 'dataset/testset/faces/cmu_0167.png', 'dataset/testset/faces/cmu_0090.png', 'dataset/testset/faces/cmu_0117.png', 'dataset/testset/faces/cmu_0441.png', 'dataset/testset/faces/cmu_0365.png', 'dataset/testset/faces/cmu_0347.png', 'dataset/testset/faces/cmu_0435.png', 'dataset/testset/faces/cmu_0069.png', 'dataset/testset/faces/cmu_0219.png', 'dataset/testset/faces/cmu_0021.png', 'dataset/testset/faces/cmu_0040.png', 'dataset/testset/faces/cmu_0344.png', 'dataset/testset/faces/cmu_0428.png', 'dataset/testset/faces/cmu_0369.png', 'dataset/testset/faces/cmu_0450.png', 'dataset/testset/faces/cmu_0262.png', 'dataset/testset/faces/cmu_0340.png', 'dataset/testset/faces/cmu_0408.png', 'dataset/testset/faces/cmu_0077.png', 'dataset/testset/faces/cmu_0188.png', 'dataset/testset/faces/cmu_0433.png', 'dataset/testset/faces/cmu_0162.png', 'dataset/testset/faces/cmu_0334.png', 'dataset/testset/faces/cmu_0058.png', 'dataset/testset/faces/cmu_0229.png', 'dataset/testset/faces/cmu_0180.png', 'dataset/testset/faces/cmu_0401.png', 'dataset/testset/faces/cmu_0197.png', 'dataset/testset/faces/cmu_0395.png', 'dataset/testset/faces/cmu_0001.png', 'dataset/testset/faces/cmu_0394.png', 'dataset/testset/faces/cmu_0233.png', 'dataset/testset/faces/cmu_0392.png', 'dataset/testset/faces/cmu_0348.png', 'dataset/testset/faces/cmu_0014.png', 'dataset/testset/faces/cmu_0267.png', 'dataset/testset/faces/cmu_0457.png', 'dataset/testset/faces/cmu_0141.png', 'dataset/testset/faces/cmu_0245.png', 'dataset/testset/faces/cmu_0232.png', 'dataset/testset/faces/cmu_0424.png', 'dataset/testset/faces/cmu_0280.png', 'dataset/testset/faces/cmu_0418.png', 'dataset/testset/faces/cmu_0041.png', 'dataset/testset/faces/cmu_0013.png', 'dataset/testset/faces/cmu_0405.png', 'dataset/testset/faces/cmu_0073.png', 'dataset/testset/faces/cmu_0339.png', 'dataset/testset/faces/cmu_0283.png', 'dataset/testset/faces/cmu_0189.png', 'dataset/testset/faces/cmu_0274.png', 'dataset/testset/faces/cmu_0220.png', 'dataset/testset/faces/cmu_0269.png', 'dataset/testset/faces/cmu_0066.png', 'dataset/testset/faces/cmu_0333.png', 'dataset/testset/faces/cmu_0432.png', 'dataset/testset/faces/cmu_0080.png', 'dataset/testset/faces/cmu_0416.png', 'dataset/testset/faces/cmu_0054.png', 'dataset/testset/faces/cmu_0407.png', 'dataset/testset/faces/cmu_0399.png', 'dataset/testset/faces/cmu_0033.png', 'dataset/testset/faces/cmu_0098.png', 'dataset/testset/faces/cmu_0183.png', 'dataset/testset/faces/cmu_0313.png', 'dataset/testset/faces/cmu_0032.png', 'dataset/testset/faces/cmu_0354.png', 'dataset/testset/faces/cmu_0039.png', 'dataset/testset/faces/cmu_0050.png', 'dataset/testset/faces/cmu_0044.png', 'dataset/testset/faces/cmu_0345.png', 'dataset/testset/faces/cmu_0321.png', 'dataset/testset/faces/cmu_0035.png', 'dataset/testset/faces/cmu_0225.png', 'dataset/testset/faces/cmu_0026.png', 'dataset/testset/faces/cmu_0458.png', 'dataset/testset/faces/cmu_0116.png', 'dataset/testset/faces/cmu_0342.png', 'dataset/testset/faces/cmu_0268.png', 'dataset/testset/faces/cmu_0460.png', 'dataset/testset/faces/cmu_0446.png', 'dataset/testset/faces/cmu_0038.png', 'dataset/testset/faces/cmu_0360.png', 'dataset/testset/faces/cmu_0279.png', 'dataset/testset/faces/cmu_0362.png', 'dataset/testset/faces/cmu_0284.png', 'dataset/testset/faces/cmu_0240.png', 'dataset/testset/faces/cmu_0328.png', 'dataset/testset/faces/cmu_0417.png', 'dataset/testset/faces/cmu_0303.png', 'dataset/testset/faces/cmu_0402.png', 'dataset/testset/faces/cmu_0111.png', 'dataset/testset/faces/cmu_0179.png', 'dataset/testset/faces/cmu_0201.png', 'dataset/testset/faces/cmu_0063.png', 'dataset/testset/faces/cmu_0136.png', 'dataset/testset/faces/cmu_0434.png', 'dataset/testset/faces/cmu_0350.png', 'dataset/testset/faces/cmu_0439.png', 'dataset/testset/faces/cmu_0099.png', 'dataset/testset/faces/cmu_0370.png', 'dataset/testset/faces/cmu_0132.png', 'dataset/testset/faces/cmu_0194.png', 'dataset/testset/faces/cmu_0210.png', 'dataset/testset/faces/cmu_0003.png', 'dataset/testset/faces/cmu_0263.png', 'dataset/testset/faces/cmu_0221.png', 'dataset/testset/faces/cmu_0351.png', 'dataset/testset/faces/cmu_0393.png', 'dataset/testset/faces/cmu_0133.png', 'dataset/testset/faces/cmu_0128.png', 'dataset/testset/faces/cmu_0102.png', 'dataset/testset/faces/cmu_0068.png', 'dataset/testset/faces/cmu_0023.png', 'dataset/testset/faces/cmu_0246.png', 'dataset/testset/faces/cmu_0184.png', 'dataset/testset/faces/cmu_0057.png', 'dataset/testset/faces/cmu_0126.png', 'dataset/testset/faces/cmu_0455.png', 'dataset/testset/faces/cmu_0291.png', 'dataset/testset/faces/cmu_0120.png', 'dataset/testset/faces/cmu_0067.png', 'dataset/testset/faces/cmu_0051.png', 'dataset/testset/faces/cmu_0377.png', 'dataset/testset/faces/cmu_0082.png', 'dataset/testset/faces/cmu_0061.png', 'dataset/testset/faces/cmu_0421.png', 'dataset/testset/faces/cmu_0336.png', 'dataset/testset/faces/cmu_0308.png', 'dataset/testset/faces/cmu_0379.png', 'dataset/testset/faces/cmu_0422.png', 'dataset/testset/faces/cmu_0230.png', 'dataset/testset/faces/cmu_0320.png', 'dataset/testset/faces/cmu_0115.png', 'dataset/testset/faces/cmu_0287.png', 'dataset/testset/faces/cmu_0181.png', 'dataset/testset/faces/cmu_0442.png', 'dataset/testset/faces/cmu_0015.png', 'dataset/testset/faces/cmu_0337.png', 'dataset/testset/faces/cmu_0290.png', 'dataset/testset/faces/cmu_0251.png', 'dataset/testset/faces/cmu_0296.png', 'dataset/testset/faces/cmu_0109.png', 'dataset/testset/faces/cmu_0097.png', 'dataset/testset/faces/cmu_0075.png', 'dataset/testset/faces/cmu_0018.png', 'dataset/testset/faces/cmu_0294.png', 'dataset/testset/faces/cmu_0235.png', 'dataset/testset/faces/cmu_0363.png', 'dataset/testset/faces/cmu_0191.png', 'dataset/testset/faces/cmu_0426.png', 'dataset/testset/faces/cmu_0084.png', 'dataset/testset/faces/cmu_0384.png', 'dataset/testset/faces/cmu_0305.png', 'dataset/testset/faces/cmu_0037.png', 'dataset/testset/faces/cmu_0447.png', 'dataset/testset/faces/cmu_0436.png', 'dataset/testset/faces/cmu_0423.png', 'dataset/testset/faces/cmu_0129.png', 'dataset/testset/faces/cmu_0019.png', 'dataset/testset/faces/cmu_0207.png', 'dataset/testset/faces/cmu_0302.png', 'dataset/testset/faces/cmu_0016.png', 'dataset/testset/faces/cmu_0092.png', 'dataset/testset/faces/cmu_0168.png', 'dataset/testset/faces/cmu_0100.png', 'dataset/testset/faces/cmu_0209.png', 'dataset/testset/faces/cmu_0266.png', 'dataset/testset/faces/cmu_0047.png', 'dataset/testset/faces/cmu_0079.png', 'dataset/testset/faces/cmu_0461.png', 'dataset/testset/faces/cmu_0327.png', 'dataset/testset/faces/cmu_0367.png', 'dataset/testset/faces/cmu_0382.png', 'dataset/testset/faces/cmu_0205.png', 'dataset/testset/faces/cmu_0311.png', 'dataset/testset/faces/cmu_0248.png', 'dataset/testset/faces/cmu_0154.png', 'dataset/testset/faces/cmu_0052.png', 'dataset/testset/faces/cmu_0250.png', 'dataset/testset/faces/cmu_0383.png', 'dataset/testset/faces/cmu_0448.png', 'dataset/testset/faces/cmu_0300.png', 'dataset/testset/faces/cmu_0086.png', 'dataset/testset/faces/cmu_0449.png', 'dataset/testset/faces/cmu_0190.png', 'dataset/testset/faces/cmu_0164.png', 'dataset/testset/faces/cmu_0030.png', 'dataset/testset/faces/cmu_0318.png', 'dataset/testset/faces/cmu_0053.png', 'dataset/testset/faces/cmu_0215.png', 'dataset/testset/faces/cmu_0165.png', 'dataset/testset/faces/cmu_0243.png', 'dataset/testset/faces/cmu_0413.png', 'dataset/testset/faces/cmu_0087.png', 'dataset/testset/faces/cmu_0315.png', 'dataset/testset/faces/cmu_0152.png', 'dataset/testset/faces/cmu_0381.png', 'dataset/testset/faces/cmu_0224.png', 'dataset/testset/faces/cmu_0444.png', 'dataset/testset/faces/cmu_0158.png', 'dataset/testset/faces/cmu_0371.png', 'dataset/testset/faces/cmu_0317.png', 'dataset/testset/faces/cmu_0452.png', 'dataset/testset/faces/cmu_0085.png', 'dataset/testset/faces/cmu_0440.png', 'dataset/testset/faces/cmu_0390.png', 'dataset/testset/faces/cmu_0282.png', 'dataset/testset/faces/cmu_0319.png', 'dataset/testset/faces/cmu_0343.png', 'dataset/testset/faces/cmu_0276.png', 'dataset/testset/faces/cmu_0070.png', 'dataset/testset/faces/cmu_0140.png', 'dataset/testset/faces/cmu_0101.png', 'dataset/testset/faces/cmu_0211.png', 'dataset/testset/faces/cmu_0031.png', 'dataset/testset/faces/cmu_0385.png', 'dataset/testset/faces/cmu_0138.png', 'dataset/testset/faces/cmu_0008.png', 'dataset/testset/faces/cmu_0295.png', 'dataset/testset/faces/cmu_0135.png', 'dataset/testset/faces/cmu_0386.png', 'dataset/testset/faces/cmu_0106.png', 'dataset/testset/faces/cmu_0110.png', 'dataset/testset/faces/cmu_0265.png', 'dataset/testset/faces/cmu_0107.png', 'dataset/testset/faces/cmu_0123.png', 'dataset/testset/faces/cmu_0326.png', 'dataset/testset/faces/cmu_0170.png', 'dataset/testset/faces/cmu_0010.png', 'dataset/testset/faces/cmu_0278.png', 'dataset/testset/faces/cmu_0182.png', 'dataset/testset/faces/cmu_0153.png', 'dataset/testset/faces/cmu_0065.png', 'dataset/testset/faces/cmu_0380.png', 'dataset/testset/faces/cmu_0396.png', 'dataset/testset/faces/cmu_0139.png', 'dataset/testset/faces/cmu_0391.png', 'dataset/testset/faces/cmu_0196.png', 'dataset/testset/faces/cmu_0322.png', 'dataset/testset/faces/cmu_0149.png', 'dataset/testset/faces/cmu_0420.png', 'dataset/testset/faces/cmu_0252.png', 'dataset/testset/faces/cmu_0255.png', 'dataset/testset/faces/cmu_0409.png', 'dataset/testset/faces/cmu_0204.png', 'dataset/testset/faces/cmu_0253.png', 'dataset/testset/faces/cmu_0292.png', 'dataset/testset/faces/cmu_0258.png', 'dataset/testset/faces/cmu_0227.png', 'dataset/testset/faces/cmu_0076.png', 'dataset/testset/faces/cmu_0464.png', 'dataset/testset/faces/cmu_0459.png', 'dataset/testset/faces/cmu_0277.png', 'dataset/testset/faces/cmu_0372.png', 'dataset/testset/faces/cmu_0124.png', 'dataset/testset/faces/cmu_0431.png', 'dataset/testset/faces/cmu_0022.png', 'dataset/testset/faces/cmu_0118.png', 'dataset/testset/faces/cmu_0091.png', 'dataset/testset/faces/cmu_0089.png', 'dataset/testset/faces/cmu_0020.png', 'dataset/testset/faces/cmu_0226.png', 'dataset/testset/faces/cmu_0024.png', 'dataset/testset/faces/cmu_0466.png', 'dataset/testset/faces/cmu_0088.png', 'dataset/testset/faces/cmu_0025.png', 'dataset/testset/faces/cmu_0056.png', 'dataset/testset/faces/cmu_0388.png', 'dataset/testset/faces/cmu_0049.png', 'dataset/testset/faces/cmu_0429.png', 'dataset/testset/faces/cmu_0009.png', 'dataset/testset/faces/cmu_0443.png', 'dataset/testset/faces/cmu_0169.png', 'dataset/testset/faces/cmu_0376.png', 'dataset/testset/faces/cmu_0078.png', 'dataset/testset/faces/cmu_0216.png', 'dataset/testset/faces/cmu_0398.png', 'dataset/testset/faces/cmu_0316.png', 'dataset/testset/faces/cmu_0214.png', 'dataset/testset/faces/cmu_0176.png', 'dataset/testset/faces/cmu_0312.png', 'dataset/testset/faces/cmu_0142.png', 'dataset/testset/faces/cmu_0114.png', 'dataset/testset/faces/cmu_0195.png', 'dataset/testset/faces/cmu_0206.png', 'dataset/testset/faces/cmu_0306.png', 'dataset/testset/faces/cmu_0222.png', 'dataset/testset/faces/cmu_0234.png', 'dataset/testset/faces/cmu_0172.png', 'dataset/testset/faces/cmu_0236.png', 'dataset/testset/faces/cmu_0217.png', 'dataset/testset/faces/cmu_0419.png', 'dataset/testset/faces/cmu_0046.png', 'dataset/testset/faces/cmu_0271.png', 'dataset/testset/faces/cmu_0324.png', 'dataset/testset/faces/cmu_0146.png', 'dataset/testset/faces/cmu_0329.png', 'dataset/testset/faces/cmu_0007.png', 'dataset/testset/faces/cmu_0285.png', 'dataset/testset/faces/cmu_0105.png', 'dataset/testset/faces/cmu_0355.png', 'dataset/testset/faces/cmu_0288.png', 'dataset/testset/faces/cmu_0122.png', 'dataset/testset/faces/cmu_0414.png', 'dataset/testset/faces/cmu_0387.png', 'dataset/testset/faces/cmu_0119.png', 'dataset/testset/faces/cmu_0083.png', 'dataset/testset/faces/cmu_0036.png', 'dataset/testset/faces/cmu_0011.png', 'dataset/testset/faces/cmu_0430.png', 'dataset/testset/faces/cmu_0144.png', 'dataset/testset/faces/cmu_0366.png', 'dataset/testset/faces/cmu_0374.png', 'dataset/testset/faces/cmu_0130.png', 'dataset/testset/faces/cmu_0004.png', 'dataset/testset/faces/cmu_0103.png', 'dataset/testset/faces/cmu_0177.png', 'dataset/testset/faces/cmu_0199.png', 'dataset/testset/faces/cmu_0293.png', 'dataset/testset/faces/cmu_0060.png', 'dataset/testset/faces/cmu_0273.png', 'dataset/testset/faces/cmu_0163.png', 'dataset/testset/faces/cmu_0257.png', 'dataset/testset/faces/cmu_0411.png', 'dataset/testset/faces/cmu_0231.png', 'dataset/testset/faces/cmu_0451.png', 'dataset/testset/faces/cmu_0228.png', 'dataset/testset/faces/cmu_0156.png', 'dataset/testset/faces/cmu_0212.png', 'dataset/testset/faces/cmu_0307.png', 'dataset/testset/faces/cmu_0198.png', 'dataset/testset/faces/cmu_0081.png', 'dataset/testset/faces/cmu_0264.png', 'dataset/testset/faces/cmu_0192.png', 'dataset/testset/faces/cmu_0108.png', 'dataset/testset/faces/cmu_0137.png', 'dataset/testset/faces/cmu_0368.png', 'dataset/testset/faces/cmu_0314.png', 'dataset/testset/faces/cmu_0259.png', 'dataset/testset/faces/cmu_0323.png', 'dataset/testset/faces/cmu_0064.png', 'dataset/testset/faces/cmu_0462.png', 'dataset/testset/faces/cmu_0131.png', 'dataset/testset/faces/cmu_0361.png', 'dataset/testset/faces/cmu_0213.png', 'dataset/testset/faces/cmu_0062.png', 'dataset/testset/faces/cmu_0072.png', 'dataset/testset/faces/cmu_0145.png', 'dataset/testset/faces/cmu_0055.png', 'dataset/testset/faces/cmu_0134.png', 'dataset/testset/faces/cmu_0470.png', 'dataset/testset/faces/cmu_0017.png', 'dataset/testset/faces/cmu_0427.png', 'dataset/testset/faces/cmu_0389.png', 'dataset/testset/faces/cmu_0034.png', 'dataset/testset/faces/cmu_0006.png', 'dataset/testset/faces/cmu_0453.png', 'dataset/testset/faces/cmu_0112.png', 'dataset/testset/faces/cmu_0281.png', 'dataset/testset/faces/cmu_0028.png', 'dataset/testset/faces/cmu_0027.png', 'dataset/testset/faces/cmu_0237.png', 'dataset/testset/faces/cmu_0171.png', 'dataset/testset/faces/cmu_0256.png', 'dataset/testset/faces/cmu_0403.png', 'dataset/testset/faces/cmu_0166.png', 'dataset/testset/faces/cmu_0244.png', 'dataset/testset/faces/cmu_0094.png', 'dataset/testset/faces/cmu_0238.png', 'dataset/testset/faces/cmu_0467.png', 'dataset/testset/faces/cmu_0148.png', 'dataset/testset/faces/cmu_0059.png', 'dataset/testset/faces/cmu_0335.png', 'dataset/testset/faces/cmu_0438.png', 'dataset/testset/faces/cmu_0186.png', 'dataset/testset/faces/cmu_0332.png', 'dataset/testset/faces/cmu_0349.png', 'dataset/testset/faces/cmu_0157.png', 'dataset/testset/faces/cmu_0193.png', 'dataset/testset/faces/cmu_0147.png', 'dataset/testset/faces/cmu_0125.png', 'dataset/testset/faces/cmu_0304.png', 'dataset/testset/faces/cmu_0352.png', 'dataset/testset/faces/cmu_0048.png', 'dataset/testset/faces/cmu_0002.png', 'dataset/testset/faces/cmu_0358.png', 'dataset/testset/faces/cmu_0437.png', 'dataset/testset/faces/cmu_0364.png', 'dataset/testset/faces/cmu_0074.png', 'dataset/testset/faces/cmu_0155.png', 'dataset/testset/faces/cmu_0185.png', 'dataset/testset/faces/cmu_0042.png', 'dataset/testset/faces/cmu_0272.png', 'dataset/testset/faces/cmu_0223.png', 'dataset/testset/faces/cmu_0406.png', 'dataset/testset/faces/cmu_0286.png', 'dataset/testset/faces/cmu_0000.png', 'dataset/testset/faces/cmu_0127.png', 'dataset/testset/faces/cmu_0208.png', 'dataset/testset/faces/cmu_0425.png', 'dataset/testset/faces/cmu_0143.png', 'dataset/testset/faces/cmu_0275.png', 'dataset/testset/faces/cmu_0175.png', 'dataset/testset/faces/cmu_0151.png', 'dataset/testset/faces/cmu_0289.png', 'dataset/testset/faces/cmu_0468.png', 'dataset/testset/faces/cmu_0297.png', 'dataset/testset/faces/cmu_0353.png', 'dataset/testset/faces/cmu_0218.png', 'dataset/testset/faces/cmu_0404.png', 'dataset/testset/faces/cmu_0445.png', 'dataset/testset/faces/cmu_0150.png', 'dataset/testset/faces/cmu_0456.png', 'dataset/testset/faces/cmu_0298.png', 'dataset/testset/faces/cmu_0241.png', 'dataset/testset/faces/cmu_0331.png', 'dataset/testset/faces/cmu_0161.png', 'dataset/testset/faces/cmu_0330.png', 'dataset/testset/faces/cmu_0254.png', 'dataset/testset/faces/cmu_0373.png', 'dataset/testset/faces/cmu_0471.png', 'dataset/testset/faces/cmu_0242.png', 'dataset/testset/faces/cmu_0045.png', 'dataset/testset/faces/cmu_0160.png', 'dataset/testset/faces/cmu_0113.png', 'dataset/testset/faces/cmu_0454.png', 'dataset/testset/faces/cmu_0301.png', 'dataset/testset/faces/cmu_0202.png', 'dataset/testset/faces/cmu_0178.png', 'dataset/testset/faces/cmu_0239.png', 'dataset/testset/faces/cmu_0410.png', 'dataset/testset/faces/cmu_0270.png', 'dataset/testset/faces/cmu_0247.png', 'dataset/testset/faces/cmu_0173.png', 'dataset/testset/faces/cmu_0465.png', 'dataset/testset/faces/cmu_0159.png', 'dataset/testset/faces/cmu_0095.png', 'dataset/testset/faces/cmu_0093.png', 'dataset/testset/faces/cmu_0357.png', 'dataset/testset/faces/cmu_0261.png', 'dataset/testset/faces/cmu_0187.png', 'dataset/testset/faces/cmu_0310.png', 'dataset/testset/faces/cmu_0096.png', 'dataset/testset/faces/cmu_0299.png', 'dataset/testset/faces/cmu_0415.png', 'dataset/testset/faces/cmu_0104.png', 'dataset/testset/faces/cmu_0309.png', 'dataset/testset/faces/cmu_0200.png', 'dataset/testset/faces/cmu_0012.png', 'dataset/testset/faces/cmu_0029.png', 'dataset/testset/faces/cmu_0260.png']\n"
     ]
    }
   ],
   "source": [
    "test_f = read_files('testset/faces')\n",
    "test_nf = read_files('testset/non-faces')\n",
    "print(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qR1DDrinraSt",
    "outputId": "0826901d-72dc-43e6-a20b-46d90d0e5b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(train_f[0]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ooC_Qub9rV0f"
   },
   "source": [
    "### Integral Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqUortnTo-T-"
   },
   "outputs": [],
   "source": [
    "def integral_image(image):\n",
    "    ii = np.zeros(image.shape)\n",
    "    s = np.zeros(image.shape)\n",
    "    new_ii = np.zeros((image.shape[0]+1, image.shape[1]+1))\n",
    "    \n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[i])):\n",
    "            s[i][j] = s[i-1][j] + image[i][j] if i-1 >= 0 else image[i][j]\n",
    "            ii[i][j] = ii[i][j-1]+s[i][j] if j-1 >= 0 else s[i][j]\n",
    "\n",
    "    new_ii[1:image.shape[0]+1, 1:image.shape[1]+1] = ii\n",
    "\n",
    "    return new_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array(Image.open(train_f[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 74,  79,  83,  90, 103, 111, 120, 125, 127, 128, 129, 131, 135,\n",
       "        134, 134, 125, 121, 114, 107],\n",
       "       [ 76,  75,  75,  78,  83, 101, 101, 113, 122, 126, 127, 120, 116,\n",
       "         99,  80,  82,  83,  88, 105],\n",
       "       [ 74,  47,  38,  31,  30,  42,  58,  78, 101, 110, 106,  80,  70,\n",
       "         46,  38,  35,  44,  50,  81],\n",
       "       [ 76,  47,  41,  40,  36,  36,  41,  58,  81,  82,  89,  67,  54,\n",
       "         54,  61,  79,  78,  78,  75],\n",
       "       [ 97,  68,  48,  49,  48,  45,  44,  51,  79, 108, 113,  85,  60,\n",
       "         52,  46,  52,  62,  75,  93],\n",
       "       [ 73,  49,  31,  34,  32,  43,  40,  47,  64, 112, 122,  88,  75,\n",
       "         56,  43,  53,  60,  76, 105],\n",
       "       [ 77,  72,  63,  64,  72,  76,  75,  62,  71, 111, 121, 101,  93,\n",
       "         83,  85,  96, 103, 113, 120],\n",
       "       [ 83,  89,  93,  83,  82,  88,  81,  69,  79, 110, 123, 110, 114,\n",
       "        117, 117, 122, 127, 128, 124],\n",
       "       [ 84,  90,  96, 106, 108, 106,  89,  72,  80, 111, 125, 113, 115,\n",
       "        130, 135, 135, 132, 131, 125],\n",
       "       [ 84,  93, 105, 114, 116, 111,  85,  68,  80, 114, 125, 111, 110,\n",
       "        125, 133, 138, 137, 131, 126],\n",
       "       [ 84,  88, 101, 111, 109,  97,  68,  73,  75, 111, 123, 107, 104,\n",
       "        113, 123, 130, 129, 127, 120],\n",
       "       [103,  73,  83,  91,  92,  87,  67,  51,  47,  73,  81,  59,  88,\n",
       "        115, 115, 108, 115, 107,  98],\n",
       "       [102,  78,  66,  75,  90,  82,  71,  61,  54,  53,  74,  94, 113,\n",
       "        119, 122, 115, 100,  93,  94],\n",
       "       [ 93,  65,  68,  78,  86,  73,  76,  78,  82,  89,  94, 110, 113,\n",
       "        107, 111, 109, 105,  97, 103],\n",
       "       [100,  70,  80,  71,  72,  53,  61,  69,  77,  88,  91,  89,  90,\n",
       "         83,  71,  95, 106, 105, 106],\n",
       "       [116,  81,  90,  74,  75,  61,  54,  54,  70,  72,  73,  83,  82,\n",
       "         96, 102,  97,  99, 104,  99],\n",
       "       [133,  87,  89,  82,  80,  67,  65,  61,  63,  70,  73,  82,  94,\n",
       "        100,  95,  97,  90,  94,  95],\n",
       "       [198,  89,  62,  55,  67,  66,  67,  68,  63,  63,  77,  92,  97,\n",
       "         95, 107,  89,  92,  89, 129],\n",
       "       [222,  59,  56,  61,  57,  72,  77,  91, 102, 105, 114, 121, 117,\n",
       "        116, 106,  94,  87,  86, 227]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n",
      " [    0.    74.   153.   236.   326.   429.   540.   660.   785.   912.\n",
      "   1040.  1169.  1300.  1435.  1569.  1703.  1828.  1949.  2063.  2170.]\n",
      " [    0.   150.   304.   462.   630.   816.  1028.  1249.  1487.  1736.\n",
      "   1990.  2246.  2497.  2748.  2981.  3195.  3402.  3606.  3808.  4020.]\n",
      " [    0.   224.   425.   621.   820.  1036.  1290.  1569.  1885.  2235.\n",
      "   2599.  2961.  3292.  3613.  3892.  4144.  4386.  4634.  4886.  5179.]\n",
      " [    0.   300.   548.   785.  1024.  1276.  1566.  1886.  2260.  2691.\n",
      "   3137.  3588.  3986.  4361.  4694.  5007.  5328.  5654.  5984.  6352.]\n",
      " [    0.   397.   713.   998.  1286.  1586.  1921.  2285.  2710.  3220.\n",
      "   3774.  4338.  4821.  5256.  5641.  6000.  6373.  6761.  7166.  7627.]\n",
      " [    0.   470.   835.  1151.  1473.  1805.  2183.  2587.  3059.  3633.\n",
      "   4299.  4985.  5556.  6066.  6507.  6909.  7335.  7783.  8264.  8830.]\n",
      " [    0.   547.   984.  1363.  1749.  2153.  2607.  3086.  3620.  4265.\n",
      "   5042.  5849.  6521.  7124.  7648.  8135.  8657.  9208.  9802. 10488.]\n",
      " [    0.   630.  1156.  1628.  2097.  2583.  3125.  3685.  4288.  5012.\n",
      "   5899.  6829.  7611.  8328.  8969.  9573. 10217. 10895. 11617. 12427.]\n",
      " [    0.   714.  1330.  1898.  2473.  3067.  3715.  4364.  5039.  5843.\n",
      "   6841.  7896.  8791.  9623. 10394. 11133. 11912. 12722. 13575. 14510.]\n",
      " [    0.   798.  1507.  2180.  2869.  3579.  4338.  5072.  5815.  6699.\n",
      "   7811.  8991.  9997. 10939. 11835. 12707. 13624. 14571. 15555. 16616.]\n",
      " [    0.   882.  1679.  2453.  3253.  4072.  4928.  5730.  6546.  7505.\n",
      "   8728. 10031. 11144. 12190. 13199. 14194. 15241. 16317. 17428. 18609.]\n",
      " [    0.   985.  1855.  2712.  3603.  4514.  5457.  6326.  7193.  8199.\n",
      "   9495. 10879. 12051. 13185. 14309. 15419. 16574. 17765. 18983. 20262.]\n",
      " [    0.  1087.  2035.  2958.  3924.  4925.  5950.  6890.  7818.  8878.\n",
      "  10227. 11685. 12951. 14198. 15441. 16673. 17943. 19234. 20545. 21918.]\n",
      " [    0.  1180.  2193.  3184.  4228.  5315.  6413.  7429.  8435.  9577.\n",
      "  11015. 12567. 13943. 15303. 16653. 17996. 19375. 20771. 22179. 23655.]\n",
      " [    0.  1280.  2363.  3434.  4549.  5708.  6859.  7936.  9011. 10230.\n",
      "  11756. 13399. 14864. 16314. 17747. 19161. 20635. 22137. 23650. 25232.]\n",
      " [    0.  1396.  2560.  3721.  4910.  6144.  7356.  8487.  9616. 10905.\n",
      "  12503. 14219. 15767. 17299. 18828. 20344. 21915. 23516. 25133. 26814.]\n",
      " [    0.  1529.  2780.  4030.  5301.  6615.  7894.  9090. 10280. 11632.\n",
      "  13300. 15089. 16719. 18345. 19974. 21585. 23253. 24944. 26655. 28431.]\n",
      " [    0.  1727.  3067.  4379.  5705.  7086.  8431.  9694. 10952. 12367.\n",
      "  14098. 15964. 17686. 19409. 21133. 22851. 24608. 26391. 28191. 30096.]\n",
      " [    0.  1949.  3348.  4716.  6103.  7541.  8958. 10298. 11647. 13164.\n",
      "  15000. 16980. 18823. 20663. 22503. 24327. 26178. 28048. 29934. 32066.]]\n"
     ]
    }
   ],
   "source": [
    "i_sample = integral_image(sample)\n",
    "print(i_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyo6azUvxvh7"
   },
   "source": [
    "### Number of Harr Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PIB1nNqynvLo",
    "outputId": "bff60487-7e09-4078-8c28-c7bc39a71db4"
   },
   "outputs": [],
   "source": [
    "features = 5;\n",
    "feature = [[2,1], [1,2], [3,1], [1,3], [2,2]];\n",
    "frameSize = 19;\n",
    "\n",
    "total_features = 0;\n",
    "count = 0\n",
    "feature_size = [0]*features\n",
    "\n",
    "for i in range(features):\n",
    "    sizeX = feature[i][0];\n",
    "    sizeY = feature[i][1];\n",
    "\n",
    "    for width in range(sizeX,frameSize+1,sizeX):\n",
    "        for height in range(sizeY, frameSize+1, sizeY):\n",
    "            for x in range(frameSize-width+1):\n",
    "                for y in range(frameSize-height+1):\n",
    "                    count+=1\n",
    "                    feature_size[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCCjMNNUxu5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of Harr Features is  63960\n",
      "There are 17100 type 1 (two vertical) features\n",
      "There are 17100 type 2 (two horizontal) features\n",
      "There are 10830 type 3 (three horizontal) features\n",
      "There are 10830 type 4 (two vertical) features\n",
      "There are 8100 type 5 (four) features\n"
     ]
    }
   ],
   "source": [
    "print('The total number of Harr Features is ', count)\n",
    "print('There are %d type 1 (two vertical) features'% feature_size[0])\n",
    "print('There are %d type 2 (two horizontal) features'% feature_size[1])\n",
    "print('There are %d type 3 (three horizontal) features'% feature_size[2])\n",
    "print('There are %d type 4 (two vertical) features'% feature_size[3])\n",
    "print('There are %d type 5 (four) features'% feature_size[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harr features extraction to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlZadirjrGwb"
   },
   "outputs": [],
   "source": [
    "class Feature_Type:\n",
    "    def __init__(self, i, j, w, h):\n",
    "        self.i = i\n",
    "        self.j = j\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        \n",
    "    def __call__(self, ii):\n",
    "        return np.sum(np.multiply(ii[self.points_y, self.points_x], self.kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertical_Two(Feature_Type):\n",
    "    def __init__(self, i, j, w, h):\n",
    "        super().__init__(i, j, w, h)\n",
    "        hh = h // 2\n",
    "        self.points_x = [i, i+w, i, i+w, \n",
    "                         i, i+w, i, i+w]\n",
    "        self.points_y = [j, j, j + hh, j + hh,\n",
    "                         j+hh, j+hh, j + h, j + h]\n",
    "        self.kernel = [1, -1, -1, 1, \n",
    "                       -1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Horizontal_Two(Feature_Type):\n",
    "    def __init__(self, i, j, w, h):\n",
    "        super().__init__(i, j, w, h)\n",
    "        hw = w // 2\n",
    "        self.points_x = [i, i+hw, i, i+hw, \n",
    "                         i+hw, i+w, i + hw, i+w]\n",
    "        self.points_y = [j, j, j + h, j + h,\n",
    "                         j, j, j + h, j + h]\n",
    "        self.kernel = [-1, 1, 1, -1, \n",
    "                       1, -1, -1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Horizontal_Three(Feature_Type):\n",
    "    def __init__(self, i, j, w, h):\n",
    "        super().__init__(i, j, w, h)\n",
    "        tw = w // 3\n",
    "        self.points_x = [i, i+tw, i, i+tw, \n",
    "                         i+tw, i+2*tw, i+tw, i+2*tw,\n",
    "                         i+2*tw, i+w, i+2*tw, i+w]\n",
    "        self.points_y = [j, j, j + h, j + h,\n",
    "                         j, j, j + h, j + h,\n",
    "                         j, j, j + h, j + h]\n",
    "        self.kernel = [-1, 1, 1, -1, \n",
    "                       1, -1, -1, 1,\n",
    "                       -1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertical_Three(Feature_Type):\n",
    "    def __init__(self, i, j, w, h):\n",
    "        super().__init__(i, j, w, h)\n",
    "        th = h // 3\n",
    "        self.points_x = [i, i+w, i, i+w,\n",
    "                         i, i+w, i, i+w,\n",
    "                         i, i+w, i, i+w]\n",
    "        self.points_y = [j, j, j+th, j+th,\n",
    "                         j+th, j+th, j+2*th, j+2*th,\n",
    "                         j+2*th, j+2*th, j+h, j+h]\n",
    "        self.kernel = [-1, 1, 1, -1, \n",
    "                       1, -1, -1, 1,\n",
    "                       -1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Four(Feature_Type):\n",
    "    def __init__(self, i, j, w, h):\n",
    "        super().__init__(i, j, w, h)\n",
    "        \n",
    "        hw = w // 2\n",
    "        hh = h // 2\n",
    "        \n",
    "        self.points_x = [i, i+hw, i, i+hw,\n",
    "                         i+hw, i+w, i+hw, i+w,\n",
    "                         i, i+hw, i, i+hw,\n",
    "                         i+hw, i+w, i+hw, i+w]\n",
    "        self.points_y = [j, j, j+hh, j+hh,\n",
    "                         j, j, j+hh, j+hh,\n",
    "                         j+hh, j+hh, j+h, j+h,\n",
    "                         j+hh, j+hh, j+h, j+h]\n",
    "        self.kernel = [-1, 1, 1, -1, \n",
    "                       1, -1, -1, 1,\n",
    "                       1, -1, -1, 1,\n",
    "                       -1, 1, 1, -11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_range(size, window_size = 19):\n",
    "    return range(0, window_size - size + 1)\n",
    "\n",
    "def enumerate_positions(shape, window_size = 19):\n",
    "    return ((i, j)\n",
    "            for j in position_range(shape[1], window_size) \n",
    "            for i in position_range(shape[0], window_size))\n",
    "\n",
    "def enumerate_shapes(shape, window_size = 19):\n",
    "    return ((h, w)\n",
    "            for w in range(shape[1], window_size + 1, shape[1])\n",
    "            for h in range(shape[0], window_size + 1, shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features:  63960\n"
     ]
    }
   ],
   "source": [
    "two_horizontal = []\n",
    "for shape in enumerate_shapes((1, 2), 19):\n",
    "    for pos in enumerate_positions(shape, 19):\n",
    "        two_horizontal.append(Horizontal_Two(pos[1], pos[0], shape[1], shape[0]))\n",
    "\n",
    "two_vertical = []\n",
    "for shape in enumerate_shapes((2, 1), 19):\n",
    "    for pos in enumerate_positions(shape, 19):\n",
    "        two_vertical.append(Vertical_Two(pos[1], pos[0], shape[1], shape[0]))\n",
    "\n",
    "three_horizontal = []\n",
    "for shape in enumerate_shapes((1, 3), 19):\n",
    "    for pos in enumerate_positions(shape, 19):\n",
    "        three_horizontal.append(Horizontal_Three(pos[1], pos[0], shape[1], shape[0]))\n",
    "\n",
    "three_vertical = []\n",
    "for shape in enumerate_shapes((3, 1), 19):\n",
    "    for pos in enumerate_positions(shape, 19):\n",
    "        three_vertical.append(Vertical_Three(pos[1], pos[0], shape[1], shape[0]))\n",
    "\n",
    "four = []\n",
    "for shape in enumerate_shapes((2, 2), 19):\n",
    "    for pos in enumerate_positions(shape, 19):\n",
    "        four.append(Four(pos[1], pos[0], shape[1], shape[0]))\n",
    "\n",
    "print('Total features: ', len(two_horizontal)+len(two_vertical)+len(three_horizontal)+len(three_vertical)+len(four))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1o-yv-zqVOq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract horizontal two feature for sample image\n",
    "# before extracting for all images\n",
    "\n",
    "two_horizontal[0](i_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_cnt = len(train_f)+len(train_nf)\n",
    "images = np.empty((total_train_cnt,19*19))\n",
    "labels = np.empty((total_train_cnt))\n",
    "for i in range(len(train_f)):\n",
    "    images[i] = np.array(Image.open(train_f[i])).reshape(19*19)\n",
    "    labels[i] = 1\n",
    "for i in range(len(train_nf)):\n",
    "    images[len(train_f)+i] = np.array(Image.open(train_nf[i])).reshape(19*19)\n",
    "    labels[len(train_f)+i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_cnt = len(test_f)+len(test_nf)\n",
    "images_test = np.empty((total_test_cnt, 19*19))\n",
    "labels_test = np.empty((total_test_cnt))\n",
    "for i in range(len(test_f)):\n",
    "    images_test[i] = np.array(Image.open(test_f[i])).reshape(19*19)\n",
    "    labels_test[i] = 1\n",
    "for i in range(len(test_nf)):\n",
    "    images_test[len(test_f)+i] = np.array(Image.open(test_nf[i])).reshape(19*19)\n",
    "    labels_test[len(test_f)+i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7o1Bld610k3Z"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('features_final.pkl'):    \n",
    "    i = 0\n",
    "    comp_feature = [0]*63960\n",
    "    for feature in two_vertical:\n",
    "        comp_feature[i] = feature\n",
    "        i+=1\n",
    "    for feature in two_horizontal:\n",
    "        comp_feature[i] = feature\n",
    "        i+=1\n",
    "    for feature in three_horizontal:\n",
    "        comp_feature[i] = feature\n",
    "        i+=1\n",
    "    for feature in three_vertical:\n",
    "        comp_feature[i] = feature\n",
    "        i+=1\n",
    "    for feature in four:\n",
    "        comp_feature[i] = feature\n",
    "        i+=1\n",
    "    with open('features_final.pkl', 'wb') as f:\n",
    "      pickle.dump(comp_feature, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('image_features_final.pkl'):\n",
    "    image_features = np.zeros((len(images),63960))\n",
    "    p = 0\n",
    "    for train_image in images:\n",
    "        i_image = integral_image(train_image.reshape((19,19)))\n",
    "        i = 0\n",
    "        comp_feature = np.zeros((63960))\n",
    "        for feature in two_vertical:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in two_horizontal:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in three_horizontal:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in three_vertical:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in four:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        image_features[p] = comp_feature\n",
    "        p+=1\n",
    "        if p%10==0:\n",
    "            print('Image %d done' % (p))\n",
    "    with open('image_features_final.pkl', 'wb') as f:\n",
    "        pickle.dump(image_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 10 done\n",
      "Image 20 done\n",
      "Image 30 done\n",
      "Image 40 done\n",
      "Image 50 done\n",
      "Image 60 done\n",
      "Image 70 done\n",
      "Image 80 done\n",
      "Image 90 done\n",
      "Image 100 done\n",
      "Image 110 done\n",
      "Image 120 done\n",
      "Image 130 done\n",
      "Image 140 done\n",
      "Image 150 done\n",
      "Image 160 done\n",
      "Image 170 done\n",
      "Image 180 done\n",
      "Image 190 done\n",
      "Image 200 done\n",
      "Image 210 done\n",
      "Image 220 done\n",
      "Image 230 done\n",
      "Image 240 done\n",
      "Image 250 done\n",
      "Image 260 done\n",
      "Image 270 done\n",
      "Image 280 done\n",
      "Image 290 done\n",
      "Image 300 done\n",
      "Image 310 done\n",
      "Image 320 done\n",
      "Image 330 done\n",
      "Image 340 done\n",
      "Image 350 done\n",
      "Image 360 done\n",
      "Image 370 done\n",
      "Image 380 done\n",
      "Image 390 done\n",
      "Image 400 done\n",
      "Image 410 done\n",
      "Image 420 done\n",
      "Image 430 done\n",
      "Image 440 done\n",
      "Image 450 done\n",
      "Image 460 done\n",
      "Image 470 done\n",
      "Image 480 done\n",
      "Image 490 done\n",
      "Image 500 done\n",
      "Image 510 done\n",
      "Image 520 done\n",
      "Image 530 done\n",
      "Image 540 done\n",
      "Image 550 done\n",
      "Image 560 done\n",
      "Image 570 done\n",
      "Image 580 done\n",
      "Image 590 done\n",
      "Image 600 done\n",
      "Image 610 done\n",
      "Image 620 done\n",
      "Image 630 done\n",
      "Image 640 done\n",
      "Image 650 done\n",
      "Image 660 done\n",
      "Image 670 done\n",
      "Image 680 done\n",
      "Image 690 done\n",
      "Image 700 done\n",
      "Image 710 done\n",
      "Image 720 done\n",
      "Image 730 done\n",
      "Image 740 done\n",
      "Image 750 done\n",
      "Image 760 done\n",
      "Image 770 done\n",
      "Image 780 done\n",
      "Image 790 done\n",
      "Image 800 done\n",
      "Image 810 done\n",
      "Image 820 done\n",
      "Image 830 done\n",
      "Image 840 done\n",
      "Image 850 done\n",
      "Image 860 done\n",
      "Image 870 done\n",
      "Image 880 done\n",
      "Image 890 done\n",
      "Image 900 done\n",
      "Image 910 done\n",
      "Image 920 done\n",
      "Image 930 done\n",
      "Image 940 done\n",
      "Image 950 done\n",
      "Image 960 done\n",
      "Image 970 done\n",
      "Image 980 done\n",
      "Image 990 done\n",
      "Image 1000 done\n",
      "Image 1010 done\n",
      "Image 1020 done\n",
      "Image 1030 done\n",
      "Image 1040 done\n",
      "Image 1050 done\n",
      "Image 1060 done\n",
      "Image 1070 done\n",
      "Image 1080 done\n",
      "Image 1090 done\n",
      "Image 1100 done\n",
      "Image 1110 done\n",
      "Image 1120 done\n",
      "Image 1130 done\n",
      "Image 1140 done\n",
      "Image 1150 done\n",
      "Image 1160 done\n",
      "Image 1170 done\n",
      "Image 1180 done\n",
      "Image 1190 done\n",
      "Image 1200 done\n",
      "Image 1210 done\n",
      "Image 1220 done\n",
      "Image 1230 done\n",
      "Image 1240 done\n",
      "Image 1250 done\n",
      "Image 1260 done\n",
      "Image 1270 done\n",
      "Image 1280 done\n",
      "Image 1290 done\n",
      "Image 1300 done\n",
      "Image 1310 done\n",
      "Image 1320 done\n",
      "Image 1330 done\n",
      "Image 1340 done\n",
      "Image 1350 done\n",
      "Image 1360 done\n",
      "Image 1370 done\n",
      "Image 1380 done\n",
      "Image 1390 done\n",
      "Image 1400 done\n",
      "Image 1410 done\n",
      "Image 1420 done\n",
      "Image 1430 done\n",
      "Image 1440 done\n",
      "Image 1450 done\n",
      "Image 1460 done\n",
      "Image 1470 done\n",
      "Image 1480 done\n",
      "Image 1490 done\n",
      "Image 1500 done\n",
      "Image 1510 done\n",
      "Image 1520 done\n",
      "Image 1530 done\n",
      "Image 1540 done\n",
      "Image 1550 done\n",
      "Image 1560 done\n",
      "Image 1570 done\n",
      "Image 1580 done\n",
      "Image 1590 done\n",
      "Image 1600 done\n",
      "Image 1610 done\n",
      "Image 1620 done\n",
      "Image 1630 done\n",
      "Image 1640 done\n",
      "Image 1650 done\n",
      "Image 1660 done\n",
      "Image 1670 done\n",
      "Image 1680 done\n",
      "Image 1690 done\n",
      "Image 1700 done\n",
      "Image 1710 done\n",
      "Image 1720 done\n",
      "Image 1730 done\n",
      "Image 1740 done\n",
      "Image 1750 done\n",
      "Image 1760 done\n",
      "Image 1770 done\n",
      "Image 1780 done\n",
      "Image 1790 done\n",
      "Image 1800 done\n",
      "Image 1810 done\n",
      "Image 1820 done\n",
      "Image 1830 done\n",
      "Image 1840 done\n",
      "Image 1850 done\n",
      "Image 1860 done\n",
      "Image 1870 done\n",
      "Image 1880 done\n",
      "Image 1890 done\n",
      "Image 1900 done\n",
      "Image 1910 done\n",
      "Image 1920 done\n",
      "Image 1930 done\n",
      "Image 1940 done\n",
      "Image 1950 done\n",
      "Image 1960 done\n",
      "Image 1970 done\n",
      "Image 1980 done\n",
      "Image 1990 done\n",
      "Image 2000 done\n",
      "Image 2010 done\n",
      "Image 2020 done\n",
      "Image 2030 done\n",
      "Image 2040 done\n",
      "Image 2050 done\n",
      "Image 2060 done\n",
      "Image 2070 done\n",
      "Image 2080 done\n",
      "Image 2090 done\n",
      "Image 2100 done\n",
      "Image 2110 done\n",
      "Image 2120 done\n",
      "Image 2130 done\n",
      "Image 2140 done\n",
      "Image 2150 done\n",
      "Image 2160 done\n",
      "Image 2170 done\n",
      "Image 2180 done\n",
      "Image 2190 done\n",
      "Image 2200 done\n",
      "Image 2210 done\n",
      "Image 2220 done\n",
      "Image 2230 done\n",
      "Image 2240 done\n",
      "Image 2250 done\n",
      "Image 2260 done\n",
      "Image 2270 done\n",
      "Image 2280 done\n",
      "Image 2290 done\n",
      "Image 2300 done\n",
      "Image 2310 done\n",
      "Image 2320 done\n",
      "Image 2330 done\n",
      "Image 2340 done\n",
      "Image 2350 done\n",
      "Image 2360 done\n",
      "Image 2370 done\n",
      "Image 2380 done\n",
      "Image 2390 done\n",
      "Image 2400 done\n",
      "Image 2410 done\n",
      "Image 2420 done\n",
      "Image 2430 done\n",
      "Image 2440 done\n",
      "Image 2450 done\n",
      "Image 2460 done\n",
      "Image 2470 done\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('image_features_test.pkl'):\n",
    "    image_features_test = np.zeros((len(images_test), 63960))\n",
    "    p = 0\n",
    "    for test_image in images_test:\n",
    "        i_image = integral_image(test_image.reshape((19,19)))\n",
    "        i = 0\n",
    "        comp_feature = np.zeros((63960))\n",
    "        for feature in two_vertical:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in two_horizontal:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in three_horizontal:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in three_vertical:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        for feature in four:\n",
    "            comp_feature[i] = feature(i_image)\n",
    "            i+=1\n",
    "        image_features_test[p] = comp_feature\n",
    "        p+=1\n",
    "        if p%10==0:\n",
    "            print('Image %d done' % (p))\n",
    "    with open('image_features_test.pkl', 'wb') as f:\n",
    "        pickle.dump(image_features_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.   2.  -2. -21.  24.  -4.  -6.  -1.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "image_features = pickle.load(open('image_features_final.pkl', 'rb'))\n",
    "features = pickle.load(open('features_final.pkl', 'rb'))\n",
    "print(image_features[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifier:\n",
    "    def __init__(self, feature_index, threshold, polarity):\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.feature_index = feature_index\n",
    "\n",
    "    def classify(self, x):\n",
    "        if self.polarity == None:\n",
    "            self.polarity = 0\n",
    "        if type(x) is np.ndarray or x == None:\n",
    "            x = 0\n",
    "        if self.threshold == None:\n",
    "            self.threshold = 0\n",
    "        return 1 if self.polarity * x < self.polarity * self.threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_weak(X, labels, features, weights):\n",
    "    tp, tn = 0, 0\n",
    "    for w, label in zip(weights, labels):\n",
    "        if label == 1:\n",
    "            tp += w\n",
    "        else:\n",
    "            tn += w\n",
    "    classifiers = []\n",
    "    total_features = X.shape[0]\n",
    "    for i, feature in enumerate(X):\n",
    "        if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "            print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "        \n",
    "        image_feature = sorted(zip(weights, feature, labels), key=lambda x: x[1])\n",
    "        pseen, nseen = 0, 0\n",
    "        pweights, nweights = 0, 0\n",
    "        min_error, b_feature, b_threshold, b_polarity = float('inf'), None, None, None\n",
    "        \n",
    "        for w, f, label in image_feature:\n",
    "            error = min(nweights + tp - pweights, pweights + tn - nweights)\n",
    "            \n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                b_feature = i\n",
    "                b_threshold = f\n",
    "                if pseen > nseen:\n",
    "                    b_polarity = 1\n",
    "                else:\n",
    "                    b_polarity = -1\n",
    "            \n",
    "            if label == 1:\n",
    "                pseen += 1\n",
    "                pweights += w\n",
    "            else:\n",
    "                nseen += 1\n",
    "                nweights += w\n",
    "        \n",
    "        clf = WeakClassifier(b_feature, b_threshold, b_polarity)\n",
    "        classifiers.append(clf)\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier(classifiers, weights, training_data, labels):\n",
    "    best_clf, best_error, best_accuracy = None, float('inf'), None\n",
    "    for clf in classifiers:\n",
    "        error, accuracy = 0, []\n",
    "        for i in range(len(training_data)):\n",
    "            miss = abs(clf.classify(training_data[i][clf.feature_index]) - labels[i])\n",
    "            # calculating the false positive rate\n",
    "            accuracy.append(miss)\n",
    "            error += weights[i] * miss\n",
    "        error = error / len(training_data)\n",
    "        if error < best_error:\n",
    "            best_clf, best_error, best_accuracy = clf, error, accuracy\n",
    "    return best_clf, best_error, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_rounds = []\n",
    "\n",
    "def train(training, labels, rounds, pos_num, neg_num):\n",
    "    alphas = []\n",
    "    clfs = []\n",
    "    weights = np.zeros(len(training))\n",
    "    \n",
    "    for x in range(len(training)):\n",
    "        \n",
    "        if labels[x] == 1:\n",
    "            weights[x] = 1.0 / (2 * pos_num)\n",
    "        else:\n",
    "            weights[x] = 1.0 / (2 * neg_num)\n",
    "    \n",
    "    X, y = np.transpose(training), labels\n",
    "    \n",
    "    for t in range(1,rounds+1,1):\n",
    "        print('Round %d Adaboost\\n' % (t))\n",
    "        weights = weights / np.linalg.norm(weights)\n",
    "        weak_classifiers = train_weak(X, y, features, weights)\n",
    "        clf, error, accuracy = best_classifier(weak_classifiers, weights, training, labels)\n",
    "        if 1.0 - error == 0:\n",
    "            beta = 1\n",
    "        else:\n",
    "            beta = error / (1.0 - error)\n",
    "        for i in range(len(accuracy)):\n",
    "            weights[i] = weights[i] * (beta ** (1 - accuracy[i]))\n",
    "        if beta == 0:\n",
    "            alpha = 1\n",
    "        else:\n",
    "            alpha = math.log(1.0/beta)\n",
    "        alphas.append(alpha)\n",
    "        clfs.append(clf)\n",
    "    return (clfs, alphas)\n",
    "#         if t in [1,3,5,10]:\n",
    "#             adaboost_rounds.append(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(image_features, labels, 10, len(train_f), len(train_nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('adaboost_final.pkl'):\n",
    "    with open('adaboost_final.pkl', 'rb') as f:\n",
    "        alphas = pickle.load(f)\n",
    "        clfs = pickle.load(f)\n",
    "#         adaboost_rounds = pickle.load(f)\n",
    "else:\n",
    "    with open('adaboost_final.pkl', 'wb') as f:\n",
    "        pickle.dump(alphas, f)\n",
    "        pickle.dump(clfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, data, labels):\n",
    "    correct = 0\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "    faces = 0\n",
    "    non_faces = 0\n",
    "    for i in range(len(data)):\n",
    "        if(labels[i]==1):\n",
    "            faces+=1\n",
    "        else:\n",
    "            non_faces+=1\n",
    "        pred = clf.classify(data[i][clf.feature_index])\n",
    "        if pred == labels[i]:\n",
    "            correct += 1  \n",
    "        else:\n",
    "            if pred == 1:\n",
    "                false_positive+=1\n",
    "            else:\n",
    "                false_negative+=1\n",
    "\n",
    "    return (correct, false_positive, false_negative, faces, non_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2157, 299, 43, 499, 2000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(clfs[0], image_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature number  1\n",
      "Type:  Horizontal Two\n",
      "Position: (8, 3)\n",
      "Width:  2\n",
      "Length:  8\n",
      "Threshold:  112.0\n",
      "Training accuracy:  0.86 \n",
      "\n",
      "Feature number  3\n",
      "Type:  Vertical Three\n",
      "Position: (11, 3)\n",
      "Width:  7\n",
      "Length:  9\n",
      "Threshold:  -1534.0\n",
      "Training accuracy:  0.67 \n",
      "\n",
      "Feature number  5\n",
      "Type:  Vertical Two\n",
      "Position: (2, 1)\n",
      "Width:  2\n",
      "Length:  2\n",
      "Threshold:  -68.0\n",
      "Training accuracy:  0.81 \n",
      "\n",
      "Feature number  10\n",
      "Type:  Vertical Two\n",
      "Position: (10, 14)\n",
      "Width:  8\n",
      "Length:  2\n",
      "Threshold:  -136.0\n",
      "Training accuracy:  0.2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1,3,5,10]:\n",
    "    feature = features[clfs[i-1].feature_index]\n",
    "    print('Feature number ', i)\n",
    "    print('Type: ', type(feature).__name__.replace('_', ' '))\n",
    "    print('Position: (%d, %d)' % (feature.i, feature.j))\n",
    "    print('Width: ', feature.w)\n",
    "    print('Length: ', feature.h)\n",
    "    print('Threshold: ', clfs[i-1].threshold)\n",
    "    print('Training accuracy: ', round((evaluate(clfs[i-1], image_features, labels)[0])/2499, 2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array(Image.open(test_f[13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Two Feature Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features[clfs[0].feature_index]\n",
    "left = feature.i\n",
    "top = feature.j\n",
    "width = feature.w\n",
    "height = feature.h\n",
    "adaboost_image = sample.copy()\n",
    "adaboost_image[top:top+height, left:left+width//2] = 255\n",
    "adaboost_image[top:top+height, left+width//2:left+width] = 0\n",
    "img = Image.fromarray(np.uint8(adaboost_image))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAD60lEQVR4nO2duXIUQRBEV6JBAiGO4HAIvg+H3+AbsQk8zgCBEAIkvH5pZDCYuR35rIra2enNaaNqqrp7D17uJj+n9Q3n5bSucF5P6xjnybSOcN7aGX5P6w9Obn+I88hYu9tmSP3SflMhaVRIGhWSRoWksYyQ8Rb7/1MU5N/F+Whaj3HeMHfffZzWV5zkLSRAu5vTIi+RMU/dT9pzKiSNCkmjQtKokDTGG2xiq0RhygM24P7CeW9aD3Hen9Y7nN+n9R7nDzfQmJZUMYjsLT4EUyFpVEgaFZJGhaQxyAwkG5HEg3yBOoIgD4J84RXOA+fkSkk8qHKQKvmKBD/E1kP2nApJo0LSqJA0KiSNQTPAR3ZCMxUHkU9xQZsJDmoTUpw4x3nHjU48l9FpJkivYZkZqZA0KiSNCkmjQtJYRsh4jm1bIbzp06sQZHHmqfscJJ14Oi1JPC6NJcUHKVOQ7EiCtMyMVEgaFZJGhaRRIWloZKdIT8VBIru0FcgBpAVgIz9IaKZMIdkAY9q2gox+Yqx1ZqRC0qiQNCokjQpJYxkh4xk2ScK1uVKXGZwba+uZSJ2BOgRNESljSIKEKXcn2bEtmz2nQtKokDQqJI0KSWNITYDqgcRWXv8vcFJ8kJqAdBgcW8sXWe8gN8KUgQ6Ntc6MVEgaFZJGhaRRIWksI2RI9YBXeUlR2JbxCSdfktd/OTjKwXbQ3ZlzshtVUhSWjtpOihRJlpmRCkmjQtKokDQqJI3xGRtRsvGBKGzPZ5CSwod/j/Qak8RABuKe8nBZ/fgE5y135TIzUiFpVEgaFZJGhaSxjJCDF9h0PeTAyTPnpFCw1eCQAykdUlKgASIHZbNGQnaw8iWpdywzIxWSRoWkUSFpVEgag2OdJUrLEU/Ea+kgYMpZ0KyMkByAzyXGP5iWrGkkiEunw5YpuL2kEMvMSIWkUSFpVEgaFZLGMkLGF+wrdwHZiP2bLdkOyoIEyXB4UJKNcFSDFB/stguyJtuykYUTy8xIhaRRIWlUSBoVksaQo5OI7FsbFblSdkPYNY183cZre5C1/CS7ofLKWOvMSIWkUSFpVEgaFZLGMkL0LClESein68E7v3wuNYGNP+WUjaU0OCQXOjaWr3LY86+WmZEKSaNC0qiQNCokjSE1AVsoIHRLaN4I4vZ8BnGyD1KWRFJ8kIdLELfrLoRlZqRC0qiQNCokjQpJYxkh+iJPEmFPcpD+x0aKIje1R2rbxIOSg+w2BTnewTZNlpmRCkmjQtKokDQqJI0hoZngac9tlmr/hbGkeiA7IkEKGsRz2YvBP1dIDkAKwR5Ov/ZymRmpkDQqJI0KSaNC0lhGyF/VhJaU0Ik1PQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200 at 0x7F2F65F54D10>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical Three Feature Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features[clfs[2].feature_index]\n",
    "left = feature.i\n",
    "top = feature.j\n",
    "width = feature.h\n",
    "height = feature.w\n",
    "adaboost_image = sample.copy()\n",
    "hh = height//3\n",
    "adaboost_image[top:top+hh, left:left+width] = 255\n",
    "adaboost_image[top+hh:top+2*hh, left:left+width] = 0\n",
    "adaboost_image[top+2*hh:top+height, left:left+width] = 255\n",
    "img = Image.fromarray(np.uint8(adaboost_image))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAADs0lEQVR4nO2dS25TQRBFn0ljh2+CCEwQO2QF7IolIWYgkJLwSfg4zPrcQUkOIpauS/eMSh372ef1oCvVr8urN8vkekZfGfw5oy2DNzM6ZvDRjDYMrpeC3zP6wyCXv8fgpoiWB8VH6psOm4i4ERE3IuJGRNxoIzI+EN8+RUH/MYPPZ3TG4FFx9eXzjC4YJG8hAVruz4i8RD7zSfWVDpyIuBERNyLiRkTcGO+JWVtlFaY8UC64vxh8OqNnDJ7M6COD32b0icEf1QeNGUkVg5U9xQdjIuJGRNyIiBsRcWOQGUg2IokH+QJ1BEFuBPnCCwbJVkiAlnf/8g1vSZsZiYgbEXEjIm5ExI3BZkC9sq9mRMVB9CkuyGaCVPsfzojaxF5oMyMRcSMibkTEjYi40UZkvCYut0IoObBXIcjDmSQmUqbgRsmjC6Q9d0ebGYmIGxFxIyJuRMQNXdl5aFGW3qMikhxANgvKlZ8bVR7AuDvazEhE3IiIGxFxIyJutBEZr4hJTG6KV+qxi+9FVN+TcnulvPx/0mZGIuJGRNyIiBsRcWNITYDqgRQfqC5cMUjxQSoS7DDIIl6em9gHbWYkIm5ExI2IuBERN9qIDKkekFlIisKxjC8M8ibJRmgcJcnMuhrcB21mJCJuRMSNiLgRETdWb4mRkmMXlzMq+zNISYEDldLNiWMZ0keCxEA+iGvKzX05Izmkua5e2WZGIuJGRNyIiBsRcaONyKD5o+x6SMPJy2qQdEMeziTdkLMY0pCyQs6QstMijbJJZvge8iZplN1mRiLiRkTciIgbEXFDV3ZWaWnxxHotOwiE0guafQPJAfi7rPGnM6IlhBy4lJ2OskzB5SWFaDMjEXEjIm5ExI2IuNFGZJwTb6sXkI2UP7Mlx0F5XEIyHG6UZCNsmkjxgXSjfDS03LKhuXafGYmIGxFxIyJuRMSNwe9Uycpe9pYUeKUcu9gUL5S3l+t12chavhJvku+xLaI+MxIRNyLiRkTciIgbbUS0lxRSsvSz6yHPHvB3qQns+FFOOXbBBofkQsdFVFc5dvS/OnAi4kZE3IiIGxFxY0hNoCwUsHTL0rxjES9bScsg3ZzkkUiKD3JzWcTL5y6ENjMSETci4kZE3IiIG21E9B95koiyk4Psf+xIUeSiZUvtMvGg5FA2sJImleWmSZsZiYgbEXEjIm5ExI0hSzOLp+ixzEq1/6qIpHogJyJBChqs53IWg5YRkgOQQkjLiPLZyzYzEhE3IuJGRNyIiBttRP4CPeOGArWElosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200 at 0x7F2F63174DD0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical Two Feature Round 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features[clfs[4].feature_index]\n",
    "left = feature.i\n",
    "top = feature.j\n",
    "width = feature.w\n",
    "height = feature.h\n",
    "adaboost_image = sample.copy()\n",
    "hh = height//2\n",
    "adaboost_image[top:top+hh, left:left+width] = 0\n",
    "adaboost_image[top+hh:top+height, left:left+width] = 255\n",
    "img = Image.fromarray(np.uint8(adaboost_image))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAD/0lEQVR4nO2dS24UQRBEx6YYG8xXfDYICXEGjsUBuQ5iZ34CgzHGDOzqxSKk2caU4q1S6Z7uia5FpjOrco7ebia/p/UD5/W0djj/TesU59m0TnBuN4abaf3Fye2PcZ4Ya3PHPFI/dNhUSBoVkkaFpFEhaSwjZHzAJkV55y59g4n8ezifTOspzlvm7pvP0/qOk7yFBGhze1rkJfLM++4rHTgVkkaFpFEhaVRIGuM9to2t8BqTgPsH54NpPcb5cFrnOH9O6yPOX+7pY1pSxSCyt/gQTIWkUSFpVEgaFZLGIDOQZsUrnOQL1BEEeRHkC89wkq3cuCsl8bh2V9qsiS8iLZtlVqRC0qiQNCokjQpJY9AMkMguJYWjaVFxEPkUF6SZINX+u9OiNiHh/tJdKU8nnsvTub30GpZZkQpJo0LSqJA0KiSNZYSMl9ikKPY/fXoVgmzOJHOQMgUvStKJ59OSxOPaWFJ8kDIFyY4kSMusSIWkUSFpVEgaFZKGRnaK9FQcJEpLvCYHkBaAjfy8KAnNtkzBM21bQZ5+Zqx1VqRC0qiQNCokjQpJYxkh4wU2SYLdnCnbDC6N5d+Jba9Qh6ApImUMSZAw5e4kO7Zlc+BUSBoVkkaFpFEhaQypCVA9kNjKv/9XOCk+SE2A0CwB156bsNsX2e8grQpM26o4ds4Dp0LSqJA0KiSNCkljGSFDqgdkFpKicCzjC04+JNkIg6Mkmdk658W0OCMqMyEkRWHrqO2kSJFkmRWpkDQqJI0KSaNC0hhfsRElBx+IwnY+g5QUPk1LcgB2Hco0JxIDeRD3lJfL7kc5pLl1Vy6zIhWSRoWkUSFpVEgaywgZDH+UrofMxL5wTtKNfQ0OGUjpkJICDRAZlE0yw/eQD8mg7GVWpELSqJA0KiSNCklDIztRWkY8Ea+lg4Aps6DpG0gOwN8lxj+aluxpZKOjdDpsmYLbSwqxzIpUSBoVkkaFpFEhaSwjZHzD3rkLyEbsz2zJcVA2JEiGw4uSbISmiRQf7LELsibbspGNE8usSIWkUSFpVEgaFZLGkNFJRPZ9BxW5Uk5DnJgL5eM2XttB1vKV7IHKnbHWWZEKSaNC0qiQNCokjWWE6CwpREnop+shew/4u9QE7O+Gc085dkGDQ3KhU2P5Ksee+VcHToWkUSFpVEgaFZLGkJqALRQQuiU07wnidj6DODkHKVsiKT7IyyWI230XwjIrUiFpVEgaFZJGhaSxjBD9R54kwk5ykP7HnhRFbmpHatvEg5KDnDYFGe9gmybLrEiFpFEhaVRIGhWSxpDQTPC0c5ul2n9lLKkeyIlIkIIG8VzOYvDLFZIDkELIyAi793KZFamQNCokjQpJo0LSWEbIf/L3lpogrll8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200 at 0x7F2F616BCFD0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Two Feature Round 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features[clfs[9].feature_index]\n",
    "left = feature.i\n",
    "top = feature.j\n",
    "width = feature.w\n",
    "height = feature.h\n",
    "adaboost_image = sample.copy()\n",
    "hh = height//2\n",
    "adaboost_image[top:top+hh, left:left+width] = 0\n",
    "adaboost_image[top+hh:top+height, left:left+width] = 255\n",
    "img = Image.fromarray(np.uint8(adaboost_image))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAD7ElEQVR4nO2dS24UQRBEx6bwAOYrPhvENbgHKy7BJTkKYsdXYDDGGJtdvViENCA2MaV4q1RNT9dE9yLDmVXlg1ebyc8ZfWPwfEaXDF7N6AaDxzPaMni0MVzM6DeD3P6Qwa2JNjfNlPql/aZC0qiQNCokjQpJYxkh4y3x31sU5N9m8OGMHjF4zdx983FGXxnEt2CANtdnhC+ROe+4n7TnVEgaFZJGhaRRIWmMN8TkVsnClAdswv3F4N0ZPWDw3ozeMfh9Ru8Z/OEmGjOSKgaZvcWHYCokjQpJo0LSqJA0Bs5A3IgYD/wCdQRBHgR+4TGDuJULd6UYj3N3pa1I8ENsPWTPqZA0KiSNCkmjQtIYNAN8Zj+YERUHkU9xQZoJUu2/NSNqE5LuT92V1lfI7Nxeeg3LvJEKSaNC0qiQNCokjWWEjGfEthXCX/r0KgRZnIlzkDIFD0rsxJMZifE4N5EUH6RMgdkRg7TMG6mQNCokjQpJo0LS0MxOkZ6Kg2Rpydd4AGkB2MzPg5LUbMsUzGnbCjL7sYnWeSMVkkaFpFEhaVRIGssIGU+JMQlX5kpdZnBqIv9MbHuFOgRNESljiEEilLtjdmzLZs+pkDQqJI0KSaNC0hhSE6B6ILmVP//PGKT4IDUBUrMkXLtvwi5fZL2DtCoIbavi0A3uORWSRoWkUSFpVEgaywgZUj3AWYhFYVvGJwb5krgRDo4SM3PkBk9mxB5R2Y0qFoWlo7aTIkWSZd5IhaRRIWlUSBoVksb4TIwo2fhAFrbnM0hJ4cOMxAOw6lDOkcAYyETcUx4uqx9lk+aRu3KZN1IhaVRIGhWSRoWksYyQweGP0vWQAydP3CB2Y1eDQw6kdEhJgQaIHJSNmeF3yJfkoOxl3kiFpFEhaVRIGhWShmZ2srQc8US+lg4CoZwFTd9APACfS46/PyNZ08hCR+l02DIFtxcLscwbqZA0KiSNCkmjQtJYRsj4QnzpLsCN2H+zJdtBWZAgDocHJW6EpokUH+y2C1yTbdnIwoll3kiFpFEhaVRIGhWSxpCjk8jsuzYqcqXshtiaC+Xrr//5t+3mhZtoz6mQNCokjQpJo0LSWEaIniWFKClD0PWQtQd8LjWBHf+U054j8Z+8dBPtORWSRoWkUSFpVEgaQ2r4iJJBUrfsiNyRxO35DM8ZJMnLRKx8sL0Gu+6iaxqDqZA0KiSNCkmjQtLQ4gPOwp7kIH5gh0WRm9ojtflcJsKNyG5TkNqFPYVymTdSIWlUSBoVkkaFpDEkNZM87bnNssfhzESyD1J2RILUGcjnsheD/1whHgALIUdG2LWXy7yRCkmjQtKokDQqJI1lhPwBNJOUEubSTqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200 at 0x7F2F6458AE10>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost rounds on train data (Accuracy, False Positive and False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Round 1\n",
      "Training accuracy: 0.86 (2157/2499)\n",
      "False positive: 0.15 (299/2000)\n",
      "False negative: 0.09 (43/499)\n",
      "\n",
      "Adaboost Round 3\n",
      "Training accuracy: 0.67 (1682/2499)\n",
      "False positive: 0.26 (522/2000)\n",
      "False negative: 0.59 (295/499)\n",
      "\n",
      "Adaboost Round 5\n",
      "Training accuracy: 0.81 (2025/2499)\n",
      "False positive: 0.03 (58/2000)\n",
      "False negative: 0.83 (416/499)\n",
      "\n",
      "Adaboost Round 10\n",
      "Training accuracy: 0.20 (509/2499)\n",
      "False positive: 0.96 (1913/2000)\n",
      "False negative: 0.15 (77/499)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1,3,5,10]:\n",
    "    correct, fp, fn, f, nf = (evaluate(clfs[i-1], image_features, labels))\n",
    "    print('Adaboost Round %d' % i)\n",
    "    print('Training accuracy: %.2f (%d/%d)' % (correct/(f+nf), correct, f+nf))\n",
    "    print('False positive: %.2f (%d/%d)' % (fp/nf, fp, nf))\n",
    "    print('False negative: %.2f (%d/%d)\\n' % (fn/f, fn, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Round 1\n",
      "Training accuracy: 0.79 (1950/2473)\n",
      "False positive: 0.08 (165/2001)\n",
      "False negative: 0.76 (358/472)\n",
      "\n",
      "Adaboost Round 3\n",
      "Training accuracy: 0.51 (1255/2473)\n",
      "False positive: 0.44 (889/2001)\n",
      "False negative: 0.70 (329/472)\n",
      "\n",
      "Adaboost Round 5\n",
      "Training accuracy: 0.81 (1992/2473)\n",
      "False positive: 0.01 (16/2001)\n",
      "False negative: 0.99 (465/472)\n",
      "\n",
      "Adaboost Round 10\n",
      "Training accuracy: 0.19 (473/2473)\n",
      "False positive: 0.99 (1990/2001)\n",
      "False negative: 0.02 (10/472)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1,3,5,10]:\n",
    "    correct, fp, fn, f, nf = (evaluate(clfs[i-1], image_features_test, labels_test))\n",
    "    print('Adaboost Round %d' % i)\n",
    "    print('Training accuracy: %.2f (%d/%d)' % (correct/(f+nf), correct, f+nf))\n",
    "    print('False positive: %.2f (%d/%d)' % (fp/nf, fp, nf))\n",
    "    print('False negative: %.2f (%d/%d)\\n' % (fn/f, fn, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Strong Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_strong_classifier(images_data, labels, rounds):\n",
    "    correct = 0\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "    faces = 0\n",
    "    non_faces = 0\n",
    "    for i in range(len(images_data)):\n",
    "        if(labels[i]==1):\n",
    "            faces+=1\n",
    "        else:\n",
    "            non_faces+=1\n",
    "        total = 0\n",
    "        ii = integral_image(images_data[i].reshape((19,19)))\n",
    "        for j in range(rounds):\n",
    "            clf = clfs[j]\n",
    "            alpha = alphas[j]\n",
    "            x = features[clf.feature_index](ii)\n",
    "            total += alpha * x\n",
    "        if total >= 0.5 * sum(alphas):\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == labels[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            if pred == 1:\n",
    "                false_positive+=1\n",
    "            else:\n",
    "                false_negative+=1\n",
    "\n",
    "    return (correct, false_positive, false_negative, faces, non_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Adaboost Strong Classifier\n",
      "Training accuracy: 0.64 (1597/2499)\n",
      "False positive: 0.36 (889/2499)\n",
      "False negative: 0.01 (13/2499)\n",
      "\n",
      "Round 3 Adaboost Strong Classifier\n",
      "Training accuracy: 0.80 (1987/2499)\n",
      "False positive: 0.01 (13/2499)\n",
      "False negative: 0.20 (499/2499)\n",
      "\n",
      "Round 5 Adaboost Strong Classifier\n",
      "Training accuracy: 0.79 (1977/2499)\n",
      "False positive: 0.01 (24/2499)\n",
      "False negative: 0.20 (498/2499)\n",
      "\n",
      "Round 10 Adaboost Strong Classifier\n",
      "Training accuracy: 0.81 (2031/2499)\n",
      "False positive: 0.05 (124/2499)\n",
      "False negative: 0.14 (344/2499)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1,3,5,10]:\n",
    "    correct, fp, fn, f, nf = evaluate_strong_classifier(images, labels, i)\n",
    "    print('Round %d Adaboost Strong Classifier' % (i))\n",
    "    print('Training accuracy: %.2f (%d/%d)' % (correct/(f+nf), correct, f+nf))\n",
    "    print('False positive: %.2f (%d/%d)' % (fp/(f+nf), fp, (f+nf)))\n",
    "    print('False negative: %.2f (%d/%d)\\n' % (fn/(f+nf), fn, (f+nf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate strong classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Adaboost Strong Classifier\n",
      "Training accuracy: 0.67 (1669/2473)\n",
      "False positive: 0.25 (621/2473)\n",
      "False negative: 0.07 (183/2473)\n",
      "\n",
      "Round 3 Adaboost Strong Classifier\n",
      "Training accuracy: 0.81 (1998/2473)\n",
      "False positive: 0.00 (4/2473)\n",
      "False negative: 0.19 (471/2473)\n",
      "\n",
      "Round 5 Adaboost Strong Classifier\n",
      "Training accuracy: 0.81 (1995/2473)\n",
      "False positive: 0.00 (7/2473)\n",
      "False negative: 0.19 (471/2473)\n",
      "\n",
      "Round 10 Adaboost Strong Classifier\n",
      "Training accuracy: 0.81 (1994/2473)\n",
      "False positive: 0.02 (51/2473)\n",
      "False negative: 0.17 (428/2473)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1,3,5,10]:\n",
    "    correct, fp, fn, f, nf = evaluate_strong_classifier(images_test, labels_test, i)\n",
    "    print('Round %d Adaboost Strong Classifier' % (i))\n",
    "    print('Training accuracy: %.2f (%d/%d)' % (correct/(f+nf), correct, f+nf))\n",
    "    print('False positive: %.2f (%d/%d)' % (fp/(f+nf), fp, (f+nf)))\n",
    "    print('False negative: %.2f (%d/%d)\\n' % (fn/(f+nf), fn, (f+nf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the threshold (False positive rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(image_features, labels, 5, len(train_f), len(train_nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('adaboost_fp.pkl'):\n",
    "#     with open('adaboost_fp.pkl', 'rb') as f:\n",
    "#         alphas = pickle.load(f)\n",
    "#         clfs = pickle.load(f)\n",
    "# else:\n",
    "#     with open('adaboost_fp.pkl', 'wb') as f:\n",
    "#         pickle.dump(alphas, f)\n",
    "#         pickle.dump(clfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 2 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 3 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 4 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 5 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 6 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 7 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 8 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 9 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 10 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 11 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 12 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 13 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 14 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 15 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 16 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 17 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 18 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 19 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 20 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 21 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 22 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 23 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 24 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n",
      "Round 25 Adaboost\n",
      "\n",
      "Trained 1000 classifiers out of 63960\n",
      "Trained 2000 classifiers out of 63960\n",
      "Trained 3000 classifiers out of 63960\n",
      "Trained 4000 classifiers out of 63960\n",
      "Trained 5000 classifiers out of 63960\n",
      "Trained 6000 classifiers out of 63960\n",
      "Trained 7000 classifiers out of 63960\n",
      "Trained 8000 classifiers out of 63960\n",
      "Trained 9000 classifiers out of 63960\n",
      "Trained 10000 classifiers out of 63960\n",
      "Trained 11000 classifiers out of 63960\n",
      "Trained 12000 classifiers out of 63960\n",
      "Trained 13000 classifiers out of 63960\n",
      "Trained 14000 classifiers out of 63960\n",
      "Trained 15000 classifiers out of 63960\n",
      "Trained 16000 classifiers out of 63960\n",
      "Trained 17000 classifiers out of 63960\n",
      "Trained 18000 classifiers out of 63960\n",
      "Trained 19000 classifiers out of 63960\n",
      "Trained 20000 classifiers out of 63960\n",
      "Trained 21000 classifiers out of 63960\n",
      "Trained 22000 classifiers out of 63960\n",
      "Trained 23000 classifiers out of 63960\n",
      "Trained 24000 classifiers out of 63960\n",
      "Trained 25000 classifiers out of 63960\n",
      "Trained 26000 classifiers out of 63960\n",
      "Trained 27000 classifiers out of 63960\n",
      "Trained 28000 classifiers out of 63960\n",
      "Trained 29000 classifiers out of 63960\n",
      "Trained 30000 classifiers out of 63960\n",
      "Trained 31000 classifiers out of 63960\n",
      "Trained 32000 classifiers out of 63960\n",
      "Trained 33000 classifiers out of 63960\n",
      "Trained 34000 classifiers out of 63960\n",
      "Trained 35000 classifiers out of 63960\n",
      "Trained 36000 classifiers out of 63960\n",
      "Trained 37000 classifiers out of 63960\n",
      "Trained 38000 classifiers out of 63960\n",
      "Trained 39000 classifiers out of 63960\n",
      "Trained 40000 classifiers out of 63960\n",
      "Trained 41000 classifiers out of 63960\n",
      "Trained 42000 classifiers out of 63960\n",
      "Trained 43000 classifiers out of 63960\n",
      "Trained 44000 classifiers out of 63960\n",
      "Trained 45000 classifiers out of 63960\n",
      "Trained 46000 classifiers out of 63960\n",
      "Trained 47000 classifiers out of 63960\n",
      "Trained 48000 classifiers out of 63960\n",
      "Trained 49000 classifiers out of 63960\n",
      "Trained 50000 classifiers out of 63960\n",
      "Trained 51000 classifiers out of 63960\n",
      "Trained 52000 classifiers out of 63960\n",
      "Trained 53000 classifiers out of 63960\n",
      "Trained 54000 classifiers out of 63960\n",
      "Trained 55000 classifiers out of 63960\n",
      "Trained 56000 classifiers out of 63960\n",
      "Trained 57000 classifiers out of 63960\n",
      "Trained 58000 classifiers out of 63960\n",
      "Trained 59000 classifiers out of 63960\n",
      "Trained 60000 classifiers out of 63960\n",
      "Trained 61000 classifiers out of 63960\n",
      "Trained 62000 classifiers out of 63960\n",
      "Trained 63000 classifiers out of 63960\n"
     ]
    }
   ],
   "source": [
    "# clfs, alphas = train(image_features, labels, 40, len(train_f), len(train_nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('cascade.pkl'):\n",
    "    with open('cascade.pkl', 'rb') as f:\n",
    "        bonus_alphas = pickle.load(f)\n",
    "        bonus_clfs = pickle.load(f)\n",
    "else:\n",
    "    with open('cascade.pkl', 'wb') as f:\n",
    "        pickle.dump(alphas, f)\n",
    "        pickle.dump(clfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting\n",
    "layers = [5, 5, 5, 10]\n",
    "\n",
    "def cascade_train(data, labels):\n",
    "    non_faces = []\n",
    "    for i in range(len(data)): \n",
    "        if labels[i] != 1:\n",
    "            non_faces.append(i)\n",
    "    prev = len(non_faces)\n",
    "    skip = 0\n",
    "    for rounds in layers:\n",
    "        if len(non_faces) == 0:\n",
    "            print(\"Stop cascade early\")\n",
    "            break\n",
    "        \n",
    "        false_positives = []\n",
    "        for ex in non_faces:\n",
    "            total = 0\n",
    "            for j in range(skip,skip+rounds):\n",
    "                clf = clfs[j]\n",
    "                alpha = alphas[j]\n",
    "                x = data[ex][clf.feature_index]\n",
    "                total += alpha * x\n",
    "            if total >= 0.5 * sum(alphas[skip:skip+rounds]):\n",
    "                pred = 1\n",
    "            else:\n",
    "                pred = 0\n",
    "            if pred == 1:\n",
    "                false_positives.append(ex)\n",
    "        non_faces = false_positives\n",
    "        print('Layer with %d rounds done' % rounds)\n",
    "        print('Number of non-faces discarded: ', prev-len(non_faces))\n",
    "        prev = len(non_faces)\n",
    "        skip += rounds\n",
    "    return prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer with 5 rounds done\n",
      "Number of non-faces discarded:  1976\n",
      "Layer with 5 rounds done\n",
      "Number of non-faces discarded:  10\n",
      "Layer with 5 rounds done\n",
      "Number of non-faces discarded:  9\n",
      "Layer with 10 rounds done\n",
      "Number of non-faces discarded:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cascade_train(image_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascade_evaluate(data, labels):\n",
    "    cur_data = []\n",
    "    for i in range(len(data)):\n",
    "        cur_data.append(i)\n",
    "    correct = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    skip = 0\n",
    "    for rounds in layers:\n",
    "        new_data = []\n",
    "        for i in cur_data:\n",
    "            total = 0\n",
    "            for j in range(skip, skip+rounds):\n",
    "                clf = clfs[j]\n",
    "                alpha = alphas[j]\n",
    "                x = data[i][clf.feature_index]\n",
    "                total += alpha * x\n",
    "            if total >= 0.5 * sum(alphas[skip:skip+rounds]):\n",
    "                pred = 1\n",
    "            else:\n",
    "                pred = 0\n",
    "            if pred == 1:\n",
    "                new_data.append(i)\n",
    "            else:\n",
    "                if labels[i]==1:\n",
    "                    fn+=1\n",
    "                else:\n",
    "                    correct+=1\n",
    "        cur_data = new_data\n",
    "        print('Layer with %d rounds done' % rounds)\n",
    "        skip += rounds\n",
    "    fp = len(cur_data)\n",
    "    return (correct, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer with 5 rounds done\n",
      "Layer with 5 rounds done\n",
      "Layer with 5 rounds done\n",
      "Layer with 10 rounds done\n",
      "Cascade Classifier on Train\n",
      "Training accuracy: 0.80 (1999/2499)\n",
      "False positive: 0.00 (1/2499)\n",
      "False negative: 0.20 (499/2499)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct, fp, fn = cascade_evaluate(image_features, labels)\n",
    "f = len(train_f)\n",
    "nf = len(train_nf)\n",
    "print('Cascade Classifier on Train')\n",
    "print('Training accuracy: %.2f (%d/%d)' % (correct/(f+nf), correct, f+nf))\n",
    "print('False positive: %.2f (%d/%d)' % (fp/(f+nf), fp, (f+nf)))\n",
    "print('False negative: %.2f (%d/%d)\\n' % (fn/(f+nf), fn, (f+nf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascade on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer with 1 rounds done\n",
      "Layer with 5 rounds done\n",
      "Layer with 10 rounds done\n",
      "Layer with 5 rounds done\n",
      "Cascade Classifier on Test\n",
      "Training accuracy: 0.81 (2000/2473)\n",
      "False positive: 0.00 (1/2473)\n",
      "False negative: 0.19 (472/2473)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct, fp, fn = cascade_evaluate(image_features_test, labels_test)\n",
    "f = len(test_f)\n",
    "nf = len(test_nf)\n",
    "print('Cascade Classifier on Test')\n",
    "print('Training accuracy: %.2f (%d/%d)' % (correct/(f+nf), correct, f+nf))\n",
    "print('False positive: %.2f (%d/%d)' % (fp/(f+nf), fp, (f+nf)))\n",
    "print('False negative: %.2f (%d/%d)\\n' % (fn/(f+nf), fn, (f+nf)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hhB7yP-EoEqc"
   ],
   "machine_shape": "hm",
   "name": "Pattern Recognition Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
